---
title: 故障排查分析汇总
date: 2020-11-05 09:58:52
tags: 
- 原创
categories: 
- bleshooting
---

__阅读更多__

<!--more-->

# 1 kubectl get nodes提示tls handshake timeout

抓包结果如下

![1-1](/images/故障排查分析汇总/1-1.png)

我们可以发现如下信息

1. tcp三次握手阶段的交互都是正常的，说明网络是通畅的
1. `seq=3566914759`的这个数据包第一次发送的时候，`len=2015`，且IP数据报头部的DF标志位置位，即不可分片。紧随其后的是多次重传，重传包的大小是`1448`

那么这个数据包发送失败的原因可能就是当前主机的mtu要远高于链路的最小mtu。调小mtu后，再次执行`kubectl get nodes`，能够正常返回结果

如何检查链路的mtu

```sh
# 发送大小是1460 + (28)字节，禁止路由器拆分数据包
ping -s 1460 -M do www.baidu.com
```

如何修改mtu（临时生效，重启后会复原），若要永久生效，那么可以通过nmtui或者nmcli配置相应的网卡连接信息

```sh
IF_NAME="eno1"

echo 1500 > /sys/class/net/${IF_NAME}/mtu
```

# 2 某个cpu的软中断si占用比例特别高

__场景复现：用wget下载一个大文件，使用`top`命令查看每个cpu的使用详情，可以发现cpu1的软中断（si）数值特别高，而其他cpu的该数值基本为0，如下图__

![2-1](/images/故障排查分析汇总/2-1.png)

机器的外网网卡为`enp0s3`，可以通过`/proc/interrupts`找到该网卡设备对应的软中断号

```sh
[root@localhost ~]$ cat /proc/interrupts | grep 'enp0s3'

#-------------------------↓↓↓↓↓↓-------------------------
 19:         11     271072          0          0   IO-APIC-fasteoi   ehci_hcd:usb1, enp0s3
#-------------------------↑↑↑↑↑↑-------------------------
```

可以看到，该网卡只有一个队列，且该队列的软中断号为`19`，可以通过`/proc/irq/19/smp_affinity`或`/proc/irq/19/smp_affinity`文件获取该中断号对应的cpu亲和性配置

对于`/proc/irq/{中断号}/smp_affinity`文件而言，其内容是cpu亲和性掩码

* 假设CPU的序号从0开始，`cpu0 = 1`，`cpu1 = cpu0 * 2`，`cpu2 = cpu1 * 2`，...
* 把该中断号亲和的cpu的数值全部相加，其结果以16进制表示，就是亲和性掩码

```
          Binary       Hex 
  CPU 0    0001         1 
  CPU 1    0010         2
  CPU 2    0100         4
  CPU 3    1000         8
+
  -----------------------
  both     1111         f
```

对于`/proc/irq/{中断号}/smp_affinity_list`文件而言，会直接列出该中断号亲和的所有cpu序号

__查看中断号19的亲和性配置__

```sh
[root@localhost 19]$ cat /proc/irq/19/smp_affinity

#-------------------------↓↓↓↓↓↓-------------------------
2
#-------------------------↑↑↑↑↑↑-------------------------

[root@localhost 19]$ cat /proc/irq/19/smp_affinity_list

#-------------------------↓↓↓↓↓↓-------------------------
1
#-------------------------↑↑↑↑↑↑-------------------------
```

__可以发现，该中断只亲和cpu1，这与我们的观测结果是一致的__

__接下来，尝试修改亲和性，想要达到的结果是：所有cpu都能够处理中断号为19的中断__

```sh
# 1 + 2 + 4 + 8 = 15 = f
echo f > /proc/irq/19/smp_affinity
```

__再次用top命令观察，发现cpu0的si数值特别高，而其他的cpu基本为0。这并不符合我们的预期。可能原因：对于网卡设备的某个队列而言，即便配置了多个亲和cpu，但是只有序号最小的cpu会生效__

![2-2](/images/故障排查分析汇总/2-2.png)

__验证刚才这个猜想，将亲和性配置为cpu2和cpu3，预期结果为：只有cpu2的si值特别高，而其他cpu基本为0__

```sh
# 4 + 8 = 12 = c
echo c > /proc/irq/19/smp_affinity
```

__用top命令观察，发现cpu2的si数值特别高，而其他的cpu基本为0，符合我们的猜想__

![2-3](/images/故障排查分析汇总/2-3.png)

__结论：__

1. 对于单队列的网卡而言，设置亲和多个cpu是无效的，只有编号最小的cpu会处理中断请求
1. 对于多队列的网卡而言，可以单独配置每个队列亲和的cpu，以达到更高的性能

## 2.1 参考

* [软中断过高问题如何解决](https://blog.csdn.net/rainharder/article/details/73198010)
* [软中断竟然是可一个CPU使劲造？](https://zhuanlan.zhihu.com/p/80619249)
