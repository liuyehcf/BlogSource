---
title: Kubernetes-阿里云公开课学习笔记
date: 2019-11-20 09:17:34
tags: 
- 摘录
categories: 
- Kubernetes
---

__阅读更多__

<!--more-->

# 1 云原生概述

## 1.1 云原生技术发展简史

首先从第一个问题进行分享，那就是“为什么要开设云原生技术公开课？”云原生、`CNCF`都是目前非常热门的关键词，但是这些技术并不是非常新鲜的内容。

1. 2004年—2007年，`Google`已在内部大规模地使用像`Cgroups`这样的容器技术
1. 2008年，`Google`将`Cgroups`合并进入了Linux内核主干
1. 2013年，`Docker`项目正式发布
1. 2014年，`Kubernetes`项目也正式发布。这样的原因也非常容易理解，因为有了容器和`Docker`之后，就需要有一种方式去帮助大家方便、快速、优雅地管理这些容器，这就是 `Kubernetes`项目的初衷。在`Google`和`Redhat`发布了`Kubernetes`之后，这个项目的发展速度非常之快
1. 2015年，由`Google`、`Redhat`以及微软等大型云计算厂商以及一些开源公司共同牵头成立了`CNCF`云原生基金会。`CNCF`成立之初，就有22个创始会员，而且`Kubernetes`也成为了`CNCF`托管的第一个开源项目。在这之后，`CNCF`的发展速度非常迅猛
1. 2017年，`CNCF`达到170个成员和14个基金项目
1. 2018年，`CNCF`成立三周年有了195个成员，19个基金会项目和11个孵化项目，如此之快的发展速度在整个云计算领域都是非常罕见的

## 1.2 我们正处于时代的关键节点

2019年正是云原生时代的关键节点，为什么这么说？我们这里就为大家简单梳理一下

从2013年`Docker`项目发布开始说起，`Docker`项目的发布使得全操作系统语义的沙盒技术唾手可得，使得用户能够更好地、更完整地打包自己的应用，使得开发者可以轻而易举的获得了一个应用的最小可运行单位，而不需要依赖任何`PaaS`能力。这对经典PaaS产业其实是一个“降维打击”

2014年的时候，`Kubernetes`项目发布，其意义在于`Google`将内部的`Borg/Omega`系统思想借助开源社区实现了“重生”，并且提出了“容器设计模式”的思想。而`Google`之所以选择间接开源`Kubernetes`而不是直接开源`Borg`项目，其实背后的原因也比较容易理解：`Borg/Omega`这样的系统太复杂了，是没办法提供给`Google`之外的人使用，但是`Borg/Omega`这样的设计思想却可以借助`Kubernetes`让大家接触到，这也是开源`Kubernetes`的重要背景

这样到了2015年-2016年，就到了容器编排“三国争霸”的时代，当时`Docker`、`Swarm`、`Mesos`、`Kubernetes`都在容器编排领域展开角逐，他们竞争的原因其实也比较容易理解， 那就是`Docker`或者容器本身的价值虽然大，但是如果想要让其产生商业价值或者说对云的价值，那么就一定需要在编排上面占据一个有利的位置

`Swarm`和`Mesos`的特点，那就是各自只在生态和技术方面比较强，其中，`Swarm`更偏向于生态，而`Mesos`技术更强一些。相比之下，`Kubernetes`则兼具了两者优势，最终在 2017年“三国争霸”的局面中得以胜出，成为了当时直到现在的容器编排标准。这一过程的代表性事件就是`Docker`公司宣布在核心产品中内置了`Kubernetes`服务，并且`Swarm`项目逐渐停止维护

到了2018年的时候，云原生技术理念开始逐渐萌芽，这是因为此时`Kubernetes`以及容器都成为了云厂商的既定标准，以“云”为核心的软件研发思想逐步形成

而到了2019年，情况似乎又将发生一些变化

## 1.3 2019年——云原生技术普及元年

为什么说2019年很可能是一个关键节点呢？我们认为2019年是云原生技术的普及元年

首先大家可以看到，在2019年，阿里巴巴宣布要全面上云，而且“上云就要上云原生”。我们还可以看到，以“云”为核心的软件研发思想，正逐步成为所有开发者的默认选项。像`Kubernetes`等云原生技术正在成为技术人员的必修课，大量的工作岗位正在涌现出来

这种背景下，“会`Kubernetes`”已经远远不够了，“懂`Kubernetes`”、“会云原生架构”的重要性正日益凸显出来。从2019年开始，云原生技术将会大规模普及，这也是为什么大家都要在这个时间点上学习和投资云原生技术的重要原因

## 1.4 云原生的技术范畴

云原生的技术范畴包括了以下几个方面：

1. 第一部分是云应用定义与开发流程。这包括应用定义与镜像制作、配置`CI/CD`、消息和`Streaming`以及数据库等
1. 第二部分是云应用的编排与管理流程。这也是`Kubernetes`比较关注的一部分，包括了应用编排与调度、服务发现治理、远程调用、API 网关以及`Service Mesh`
1. 第三部分是监控与可观测性。这部分所强调的是云上应用如何进行监控、日志收集、Tracing以及在云上如何实现破坏性测试，也就是混沌工程的概念
1. 第四部分就是云原生的底层技术，比如容器运行时、云原生存储技术、云原生网络技术等
1. 第五部分是云原生工具集，在前面的这些核心技术点之上，还有很多配套的生态或者周边的工具需要使用，比如流程自动化与配置管理、容器镜像仓库、云原生安全技术以及云端密码管理等
1. 最后则是`Serverless`。`Serverless`是一种`PaaS`的特殊形态，它定义了一种更为“极端抽象”的应用编写方式，包含了`FaaS`和`BaaS`这样的概念。而无论是`FaaS`还是`BaaS`，其最为典型的特点就是按实际使用计费（Pay as you go），因此`Serverless`计费也是重要的知识和概念

## 1.5 云原生思想的两个理论

在了解完云原生的技术范畴之后你就会发现，其所包含的技术内容还是很多的，但是这些内容的技术本质却是类似的。云原生技术的本质是两个理论基础。

1. __第一个理论基础是：不可变基础设施__。这一点目前是通过容器镜像来实现的，其含义就是应用的基础设施应该是不可变的，是一个自包含、自描述可以完全在不同环境中迁移的东西
1. __第二个理论基础就是：云应用编排理论__。当前的实现方式就是`Google`所提出来的“容器设计模式”，这也是本系列课程中的`Kubernetes`部分所需主要讲解的内容

## 1.6 基础设施向云演进的过程

首先为大家介绍一下“不可变基础设施”的概念。其实，应用所依赖的基础设施也在经历一个向云演进的过程，举例而言，对于传统的应用基础设施而言，其实往往是可变的。

大家可能经常会干这样一件事情，比如需要发布或者更新一个软件，那么流程大致是这样的，先通过`SSH`连到服务器，然后手动升级或者降级软件包，逐个调整服务器上的配置文件，并且将新代码直接都部署到现有服务器上。因此，这套基础设施会不断地被调整和修改

但是在云上，对“云”友好的应用基础设施是不可变的

这种场景下的上述更新过程会这么做：一旦应用部署完成之后，那么这套应用基础设施就不会再修改了。如果需要更新，那么需要现更改公共镜像来构建新服务直接替换旧服务。而我们之所以能够实现直接替换，就是因为容器提供了自包含的环境（包含应用运行所需的所有依赖）。所以对于应用而言，完全不需要关心容器发生了什么变化，只需要把容器镜像本身修改掉就可以了。因此，对于云友好的基础设施是随时可以替换和更换的，这就是因为容器具有敏捷和一致性的能力，也就是云时代的应用基础设施

所以，总结而言，云时代的基础设施就像是可以替代的“牲口”，可以随时替换；而传统的基础设施则是独一无二的“宠物”，需要细心呵护，这就体现出了云时代不可变基础设施的优点

## 1.7 基础设施向云演进的意义

所以，像这样的基础设施向“不可变”演进的过程，为我们提供了两个非常重要的优点

1. 基础设施的一致性和可靠性。同样一个镜像，无论是在美国打开，在中国打开，还是在印度打开都是一样的。并且其中的`OS`环境对于应用而言都是一致的。而对于应用而言，它就不需要关心容器跑在哪里，这就是基础设施一致性非常重要的一个特征
1. 这样的镜像本身就是自包含的，其包含了应用运行所需要的所有依赖，因此也可以漂移到云上的任何一个位置

此外，云原生的基础设施还提供了简单、可预测的部署和运维能力。由于现在有了镜像，应用还是自描述的，通过镜像运行起来的整个容器其实可以像`Kubernetes`的`Operator`技术一样将其做成自运维的，所以整个应用本身都是自包含的行为，使得其能够迁移到云上任何一个位置。这也使得整个流程的自动化变得非常容易

应用本身也可以更好地扩容，从1个实例变成100个实例，进而变成1万个实例，这个过程对于容器化后的应用没有任何特殊的。最后，我们这时也能够通过不可变的基础设施来地快速周围的管控系统和支撑组件。因为，这些组件本身也是容器化的，是符合不可变基础设施这样一套理论的组件

以上就是不可变基础设施为用户带来的最大的优点

## 1.8 云原生关键技术点

当我们回过头来看云原生关键技术点或者说它所依赖的技术理论的时候，可以看到主要有这样的四个方向：

1. 如何构建自包含、可定制的应用镜像
1. 能不能实现应用快速部署与隔离能力
1. 应用基础设施创建和销毁的自动化管理
1. 可复制的管控系统和支撑组件

# 2 Kubernetes 网络模型进阶

## 2.1 Service

1. 一组Pod组成一组功能后端
1. 定义一个稳定的虚IP作为访问前端，一般还附赠一个DNS域名，Client无需感知Pod的细节
1. kube-proxy是实现核心，隐藏了大量复杂性，通过apiserver监控Pod/Service的变化，反馈到LB配置中
1. LB的实现机制与目标解耦，可以是个用户态进程，也可以是一堆精心设计的Rules（iptables/ipvs）

__如何实现一个LVS版Service__

```sh
# 第一步，绑定VIP到本地（欺骗内核）
ip route add to local 192.168.166.166/32 dev lo

# 第二步，为这个虚IP创建一个IPVS的virtual server
ipvsadm -A -t 192.168.166.166:16666 -s rr -p 600

# 第三步，为这个IPVS service创建相应的real server
ipvsadm -a -t 192.168.166.166:16666 -r 127.0.0.1:22 -m
```

# 3 参考

* [k8s-阿里云公开课](https://edu.aliyun.com/course/1651?spm=5176.10731542.0.0.785020be217oeD)

