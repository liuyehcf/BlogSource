---
title: 计算机体系结构
date: 2021-11-16 09:19:25
mathjax: true
tags: 
- 摘录
categories: 
- System Architecture
---

**阅读更多**

<!--more-->

# 1 概述

## 1.1 引言

**系统和系统架构：**

1. **系统是为实现一个或多个所声明的目标而组织的相互关联的要素的组合**
1. **系统架构是系统组件的组织结构、它们之间的关系、与环境的关系、以及指导其设计和进化的原则**

**体系结构的定义：**

1. **设计、选择和连接硬件组件以及设计硬件/软件接口，以创建一个满足功能、性能、能耗、成本和其他具体目标的计算系统的科学和艺术**
1. **体现为描述计算机系统的功能、结构组织和实现的一组规则和方法**
* **广义：计算机体系结构指计算机（硬件）系统的抽象表示，基于这些抽象表示使得我们可以更好地使用可用的制造技术实现（信息处理）硬件系统，高效地设计与实现（信息处理）软件系统**

**计算机体系结构研究范畴：**

* **早期定义（Amdahl, Blaauw, and Brooks, 1964）：程序员可见的计算系统的属性。包括：概念性的结构和功能行为。不包括：数据流和控制流的组织、逻辑设计以及物理实现**
* **狭义：计算机体系结构是软件设计者与硬件设备设计者（VLSI）之间的中间层（ISA），以及微体系结构**
* **扩展的观点：计算机体系结构包括：算法层、程序/语言层、系统软件层、ISA层、微体系结构、逻辑电路层、以及器件层**

**计算机组成与实现：**

* **计算机组成（Computer Organization or Microarchitecture）：ISA的逻辑实现。包括，物理机器级中的数据流和控制流的组成以及逻辑设计等**
* **计算机实现（Computer Implementation）：计算机组成的物理实现。包括，`CPU`，`MEMORY`等的物理结构，器件的集成度、速度，模块、插件、底板的划分与连接、信号传输、电源、冷却及整机装配技术等**

## 1.2 量化设计与分析基础

**管理复杂性：**

* 将工程师或计算机科学家与门外汉区分开来的特征之一是管理复杂性的系统方法
* 现代数字系统是由数百万甚至数十亿个晶体管组成的。没有人能够通过写出描述每个晶体管中电子运动的方程并同时解出所有方程来理解这些系统
* **管理复杂性的方法：抽象（Abstraction）+ 原则（Discipline）+ 3'Y**

**影响体系结构技术发展的主要因素：**

* 产品应用方面：`PC/Server => IoT, Mobile/Cloud`
* 集成电路技术方面：
    * 登纳德缩放比例定律的终结：功耗成为关键制约条件
    * Moore定律的终结：晶体管的集成度提高延缓
* 体系结构方面
    * 挖掘指令级并行性方面的限制和低效，04年结束了单处理器时代
    * Amdahl定律暗示了简单多核时代的结束

## 1.3 定量分析基础

**过去数十年间，计算机系统设计方面的巨大变化**

* 在过去的50年，`Moore's law`和`Dennard scaling`（登纳德缩放比例定律）主宰着芯片产业的发展
    * `Moore`在1965年预测：晶体管数量随着尺寸缩小按接近平方关系增长（每18个月翻倍）
    * `Dennard`在1974年预测：晶体管尺寸变小，功耗会同比变小（相同面积下功耗不变）
    * 工艺技术的进步可在不改变软件模型的情况下，持续地提高系统性能/能耗比
* 最近10年间，工艺技术的发展受到了很大制约
    * Dennard scaling over（supply voltage ~fixed）
    * Moore's Law（cost/transistor）over?
    * Energy efficiency constrains everything
* 功耗问题成为系统结构设计必须考虑的问题
* 软件设计者必须考虑
    * Parallel systems
    * Heterogeneous systems

**有关体系结构的新旧观念**

* **旧观念：**
    * 能源很便宜，晶体管很贵
    * 通过编译、体系结构创新来增加指令级并行
    * 乘法器速度较慢，访存速度比较快
    * 单处理器性能，每1.5年翻倍
* **新观念：**
    * 能源很贵，晶体管很便宜
    * 挖掘指令级并行的收益越来越小
    * 乘法器速度提升了，访存成为瓶颈
    * `Power Wall + ILP Wall + Memory Wall = Brick Wall`，单处理器性能，每5年翻倍
    * 每2年，单个芯片上的处理器数量翻倍

**性能：**

* 性能度量
    * 响应时间
    * 吞吐率
* CPU执行时间=`IC * CPI * T`
    * `CPI`指的是`Cycles per Instruction`
* `Latency`与`Bandwidth`
    * `Latency`指单个任务的执行时间，`Bandwidth`指单位时间完成的任务量（rate）
    * `Latency`的提升滞后于带宽的提升（在过去的30年）
* `Amdahl's Law`用来度量加速比
    * 性能提升受限于任务中可加速部分所占的比例
    * 应用于多处理器系统的基本假设：在给定的问题规模下，随着处理器数目的增加性能的变化
* `Benchmarks`：指一组用于测试的程序
    * 比较计算机系统的性能（算术平均、调和平均、几何平均）

## 1.4 相关课件

* [Chapter-1.1](/resources/System-Architecture/1-1.pdf)
* [Chapter-1.2](/resources/System-Architecture/1-2.pdf)
* [Chapter-1.3](/resources/System-Architecture/1-3.pdf)

# 2 ISA

## 2.1 ISA的基本概念

**什么是指令集架构？**

* 软件子系统与硬件子系统的关键界面
* 一组直接由硬件执行的指令，包括
    * 程序员可见的机器状态
    * 程序员可见的指令集合（操作机器状态的指令）
* 应具备的特征（七个衡量指标）
    1. 成本
    1. 简洁性
    1. 架构和具体实现分离：可持续多代，以保持向后兼容
    1. 可扩展空间：可用于不同应用领域（desktops、servers、embedded applications）
    1. 程序大小：所生成的代码占用空间小
    1. 易于编程/编译/链接：为高层软件的实现与开发提供方便的功能
    1. 性能：方便低层硬件子系统高效实现

**重要的系统界面（System Interface）：**

* `ISA`界面
* `ABI`界面

**`ISA`：用户级`ISA`+特权级`ISA`**

* 用户级ISA适用于操作系统和应用程序
* 特权级ISA适用于硬件资源的管理（操作系统）

**ISA必须说明哪些东西？**

* 指令格式
* 存储器寻址
* 操作数的类型和大小
* 所支持的操作
* 控制转移类指令

**尾端问题：在一个字内部的字节顺序问题，以int（`0x12345678`）为例**

* `Little Endian`：高位在前，但是每个字节内部的`bit`还是按原来的顺序存放，即`0x78->0x56->0x34->0x12`
* `Big Endian`：低位在前，即`0x12->0x34->0x56->0x78`

**寻址方式：**

| Model | Example | Meaning | When used |
|:--|:--|:--|:--|
| Register | `Add R1, R2` | `R1 ← R1 + R2` | 操作数在寄存器中 |
| Immediate | `Add R1, 100` | `R1 ← R1 + 100` | 立即数寻址，常量 |
| Register Indirect | `Add R1, (R2)` | `R1 ← R1 + Mem(R2)` | `R2`存储的是地址 |
| Displacement | `Add R1, (R2 + 16)` | `R1 ← R1 + Mem(R2 + 16)` | 访问局部变量 |
| Absolute | `Add R1, (1000)` | `R1 ← R1 + Mem(1000)` | 访问静态变量 |
| Indexed | `Add R1, (R2 + R3)` | `R1 ← R1 + Mem(R2 + R3)` | 偏移寻址，`R2 = base`、`R3 = index` |
| Scaled Index | `Add R1, (R2 + s * R3)` | `R1 ← R1 + Mem(R2 + s * R3)` | `s = scale factor(2,4,8)` |
| Post-increment | `Add R1, (R2)+` | `R1 ← R1 + Mem(R2)`</br>`R2 ← R2 + s` | 向后跳过`array`，其中`s = element size` |
| Pre-decrement | `Add R1, -(R2)` | `R2 ← R2 - s`</br>`R1 ← R1 + Mem(R2)` | 向前跳过`array`，其中`s = element size` |

**操作数的类型、表示和大小：**

* 操作数类型和操作数表示是软硬件的主要界面之一
* 操作数类型：是面向应用、面向软件系统所处理的各种数据类型
* 操作数的表示：操作数在机器中的表示，硬件结构能够识别，指令系统可以直接使用的表示格式

**控制类指令：**

1. 条件分支`Conditional Branch`
1. 跳转`Jump`
1. 过程调用`Procedure calls`
1. 过程返回`Procedure returns`

**指令格式选择策略**

* 如果代码规模最重要，那么使用变长指令格式
* 如果性能至关重要，使用固定长度指令
* 有些嵌入式CPU附加可选模式，由每一应用自己选择性能还是代码量

## 2.2 ISA的功能设计

**功能设计：**

* 任务：确定硬件支持哪些操作
* 方法：统计的方法

**CISC：**

* 目标：强化指令功能，减少运行的指令条数，提高系统性能
* 方法：面向目标程序的优化，面向高级语言和编译器的优化

**RISC：**

* 目标：通过简化指令系统，用高效的方法实现最常用的指令
* 方法：充分发挥流水线的效率，降低CPI

### 2.2.1 CISC

**目标：强化指令功能，减少指令条数，以提高系统性能**

**基本优化方法：**

1. **面向目标程序的优化是提高计算机系统性能最直接的方法**
    * 优化目标：
        * 缩短程序长度
        * 缩短程序的执行时间
    * 优化方法：
        * 统计分析目标程序执行情况，找出使用频率高，执行时间长的指令或指令串
        * 优化使用频度高的指令
        * 用心得指令代替使用频度高的指令串
    * 主要优化途径：
        1. 增强运算型指令的功能
        1. 增强数据传送类指令的功能
        1. 增强程序控制指令的功能
1. **面向高级语言和编译程序改进指令系统**
    * 优化目标：
        * 缩小`HL-ML`之间的差距
    * 优化方法：
        1. 增强面向`HL`和`Compiler`支持的指令功能
            * 统计分析源程序中各种语句的使用频度和执行时间
            * 增强相关指令的功能，优化使用频度高、执行时间长的语句
            * 增加专门指令，以缩短目标程序长度，减少目标程序执行时间，缩短编译时间
        2. 高级语言计算机系统：缩小`HL`和`ML`的差别
            * 极端：`HL=ML`，即所谓的高级语言计算机高级语言不需要经过编译，直接由机器硬件来执行
            * 如`LISP`机，`PROLOG`机
        3. 支持操作系统的优化实现：特权指令
            * 处理器工作状态和访问方式的转换
            * 进程的管理和切换
            * 存储管理和信息保护
            * 进程同步和互斥，信号量的管理等

### 2.2.2 RISC

**目标：通过简化指令系统，用最高效的方法实现最常用的指令**

**`RISC`是一种计算机体系结构的设计思想，它不是一种产品**

**`RISC`是近代计算机体系结构发展史中的一个里程碑**

**早期对RISC特点的描述：**

* 大多数指令在单周期内完成
* 采用`Load/Store`结构
* 硬布线控制逻辑
* 少指令和寻址方式的种类
* 固定的指令格式
* 注重代码的优化

**从目前的发展看，`RISC`体系结构还应具有如下特点：**

* 面向寄存器结构
* 十分重视流水线的执行效率－尽量减少断流
* 重视优化编译技术

**减少指令平均执行周期数是`RISC`思想的精华**

**`RISC`如何降低`CPI`：**

* 硬件方面：
    * 硬布线控制逻辑
    * 减少指令和寻址方式的种类
    * 使用固定格式
    * 采用Load/Store
    * 指令执行过程中设置多级流水线
* 软件方面：十分强调优化编译的作用

### 2.2.3 典型ISA

#### 2.2.3.1 MIPS

**MIPS是最典型的RISC 指令集架构：**

* `Stanford`（1980）提出
* 第一个商业实现是`R2000`（1986）
* 最初的设计中，其整数指令集仅有58条指令，直接实现单发射、顺序流水线
* 30年来，逐步增加到约400条指令。

**主要特征：**

* `Load/Store`型结构
* `ALU`类指令的操作数来源于寄存器或立即数
* 降低了`ISA`和硬件的复杂性，方便了流水线的实现
* 依赖于优化编译技术

**主要缺陷：**

* 针对特定的微体系架构的实现方式（5级流水、单发射、顺序流水线）进行过度的优化设计
* `ISA`对位置无关的代码（position-independent code, PIC）支持不足
* 16位位宽立即数消耗了大量编码空间，只有少量的编码空间可供扩展指令
* 乘除指令使用了特殊的寄存器（`HI`，`LO`），导致上下文切换内容、指令条数、代码尺寸增加，微架构实现复杂
* 除了技术方面，`MIPS`是非开放的专属指令集，不能自由使用

#### 2.2.3.2 SPARC

**`Sun Microsystems`的专属指令集**

**`SPARC V8`主要特征**

* 用户级整型`ISA`90条指令
* 硬件支持`IEEE 754-1985`标准的浮点数50条
* 特权级指令20条

**主要问题：**

* `SPARC`使用了寄存器窗口来加速函数调用。当函数调用所需的栈空间超过了窗口的寄存器数，性能会急剧下降。对于所有的实现来说，寄存器窗口都消耗很大的面积和功耗
* 分支使用条件码。这些条件码由于在一些指令之间创建了额外的依赖关系，增加了体系结构状态并使实现复杂化
* `load`和`store`相邻寄存器对的指令。对于简单的微体系结构很有吸引力，可以在增加很少硬件复杂性的情况下提高吞吐量。遗憾的是当使用寄存器重命名时使实现复杂化，因为在寄存器文件中数据在物理上可能不再相邻
* 浮点寄存器文件和整数寄存器文件之间的移动必须使用内存系统作为中介，限制了系统性能
* 唯一的原子内存操作是`fetch-and-store`，这对于实现许多无等待的数据结构是不够的

#### 2.2.3.3 Alpha（DEC）

**主要特征：**

* 摒弃了当时非常吸引人的特性，如分支延迟、条件码、寄存器窗口等
* 创建了64位寻址空间、设计简洁、实现简单、高性能的ISA
* `Alpha`架构师仔细地将特权体系结构和硬件平台的大部分细节隔离在抽象接口（特权体系结构库）后面（PALcode）

**主要问题：DEC对顺序微架构的Alpha进行了过度优化，并添加了一些不太适合现代实现的特性**

* 为了追求高时钟频率，`ISA`的原始版本避免了8位和16位的`load/store`指令，实际上创建了一个字寻址的内存系统。为了补偿广泛使用这些（非字）操作的应用程序性能，添加了特殊的未对齐的`load/store`指令以及一些整数指令来加速重新对齐操作
* 为了方便长延迟浮点指令的乱序完成，`Alpha`有一个非精确的浮点陷阱模型。这一决定单独来看是可以的。但是`ISA`还规定：如果使用这种浮点陷阱模型，必须由软件处理例程来给出异常标记和默认值
* `Alpha`缺少整数除法指令，建议使用软件牛顿迭代法实现，导致浮点除法速度高于整数除法
* 与其他前期的`RISC`一样，没有预先考虑可能的压缩指令集扩展，因此没有足够的操作码空间来进行更新
* `ISA`包含有条件的`mov`操作，这使得带有寄存器重命名的微架构复杂化
* 使用商业`Alpha ISAs`的一个重要风险：它们可能会被摒弃

#### 2.2.3.4 ARMv7

**`ARMv7`是32位`RISC ISA`**

* 使用最广的体系结构
    * 当我们权衡指令集（选择`vs`重新设计）时，`ARMv7`是一个自然的选择
    * 大量的软件已经移植到该`ISA`上，在嵌入式和移动设备中无处不在
* 是一个封闭的标准，剪裁或扩充是不允许的，即使是微架构的创新也仅限于那些能够获得ARM所称的架构许可的组织
* `ARMv7`十分庞大复杂。整型类指令600+条

**即使知识产权不是问题，它仍然存在一些技术缺陷：**

* 不支持64位地址，`ISA`缺乏硬件支持`IEEE754-2008`标准（`ARMv8`纠正了这些缺陷）
* 特权体系结构的细节渗透到用户级体系结构的定义中
* `ISA`中包含了许多实现复杂的特性。例如程序计数器PC是整数寄存器组的成员，这意味着几乎任何指令都可以改变控制流（比如`ADD`指令）

#### 2.2.3.5 ARMv8

**2011年，`ARM`发布新的`ISA ARMv8`**

* 64位地址；扩展了整型寄存器组
* 摒弃了`ARMv7`中实现复杂的一些特性

**主要问题：**

* 使用条件码
* 存在许多特殊的寄存器
* 指令集更加厚重：1070条指令，53种格式，8种寻址方式。说明文档达到了5778页
* 以暴露底层实现的方式将用户级`ISA`和特权级`ISA`紧密地结合在一起
* 随着`ARMv8`的引入，`ARM`不再支持压缩指令编码
* `ARMv8`也是一个封闭的标准

#### 2.2.3.6 OpenRISC

**OpenRISC项目是一个开放源码处理器设计项目**

* 来源于`Hennessy`和`Patterson`的体系结构教科书`DLX ISA`
* 适用于教学、科研和工业界的实现

**主要问题：**

* OpenRISC项目主要是开源处理器设计项目，而不是开源的`ISA`规格说明，ISA和实现是紧密耦合的
* 固定的32位编码与16位立即数阻碍了压缩`ISA`扩展
* 不支持`IEEE 754-2008`标准
* 用于分支和有条件mov的条件码使高性能实现复杂化
* `ISA`对位置无关的寻址方式支持较弱
* `OpenRISC`不利于虚拟化。从异常返回的指令`L.RFE`，定义为在用户模式下功能，而不是捕获

#### 2.2.3.7 80x86

**`Intel 8086`架构是过去40年里 笔记本电脑、台式机和服务器市场上最流行的指令集**

* 除了嵌入式系统领域，几乎所有流行的软件都被移植到x86上，或者是为x86开发的
* 它受欢迎的原因有很多：该架构在`IBM PC`诞生之初的偶然可用性；英特尔专注于二进制兼容性；它们积极的卓有成效的微结构实现；以及他们的前沿制造技术
* 指令集设计质量并不是它流行的原因之一

**主要问题：**

* 1300条指令，许多寻址方式，很多特殊寄存器，多种地址翻译方式，从`AMD K5`微架构开始，所有的`Intel`支持乱序执行的微结构，都是动态地将x86指令翻译为内部的`RISC`风格的指令集。
* 不利于虚拟化。因为一些特权指令在用户模式下会无声地失败，而不是被捕获。`VMware`的工程师们用动态二进制翻译软件解决了这一缺陷
* `ISA`的指令长度为任意整数字节数，最多为15个字节，数量较少的短操作码已经被随意使用
* `ISA`有数量极少的寄存器组
* 大多数整数寄存器在`ISA`中执行特殊功能，加剧了体系结构寄存器的不足
* 更糟糕的是，大多数x86指令只有一种破坏性的指令格式，它会覆盖其中一个源操作数
* 一些`ISA`特性，包括隐式条件码和带有谓词的mov操作，在微架构中实现复杂

**80x86是一个专有指令集**

#### 2.2.3.8 小结

|  | MIPS | SPARAC | Alpha | ARMv7 | ARMv8 | OpenRISC | 80x86 |
|:--|:--|:--|:--|:--|:--|:--|:--|
| Free and Open |  | ✅ |  |  |  | ✅ |  |
| 64-bit Address | ✅ | ✅ | ✅ |  | ✅ | ✅ | ✅ |
| Compressed Instructions | ✅ |  |  | ✅ |  |  | Partial |
| Separate Privileged ISA |  |  | ✅ |  |  |  |  |
| Position-Indep. Code | Partial |  |  | ✅ | ✅ |  | ✅ |
| IEEE 754-2008 |  |  |  |  | ✅ |  | ✅ |
| Classically Virtualizable | ✅ | ✅ | ✅ |  | ✅ |  |  |

## 2.3 ISA的实现

**通用的`ISA`的设计理念（指导思想）：**

* 能适应从最袖珍的嵌入式控制器，到最快的高性能计算机等各种规模的处理器
* 能兼容各种流行的软件栈和编程语言
* 适应所有实现技术，包括现场可编程门阵列（FPGA）、专用集成电路（ASIC）、全定制芯片，甚至未来的技术
* 对所有微体系结构实现方式都有效。例如：
    * 微程序或硬布线控制；顺序或乱序执行流水线；单发射或超标量等等
* 支持定制化，成为定制专用加速器的基础。随着摩尔定律的消退，加速器的重要性日益提高
* 基础的指令集架构是稳定的。避免被弃用，如过去的`AMD Am29000`、`Digital Alpha`、`Digital VAX`、`Hewlett Packard PA-RISC`、`Intel i860`、`Intel i960`、`Motorola 88000`、以及`Zilog Z8000`
* 完全开源

**技术目标：**

* 将`ISA`分成基础`ISA`和可选的扩展部分
    * `ISA`的基础部分足够简单、完整，可以用于教学和嵌入式处理器，包括定制加速器的控制单元。它足够完整，可以运行软件栈
    * 扩展部分提高计算的性能，并支持多处理机并行
    * 支持32位和64位地址空间
* 方便根据应用需求扩展`ISA`（指令集扩展）
    * 包括紧耦合功能单元和松耦合协处理器
* 支持变长指令集扩展
    * 既为了提高代码密度，也为了扩展可能的自定义`ISA`扩展的空间
* 提供对现代标准的有效硬件支持
* 用户级`ISA`和特权级`ISA`是正交的（相互独立，互不依赖）
    * 在保持用户应用程序二进制接口（ABI）兼容性的同时，允许完全虚拟化，并允许在特权`ISA`中进行实验测试

**`RISC-V ISA`的特点：**

* **完全开源**
    * 它属于一个开放的，非营利性质的`RISC-V`基金会
    * 开源采用`BSD`协议（企业完全自由免费使用，允许企业添加自有指令而不必开放共享以实现差异化发展）
* **架构简单**
    * 没有针对某一种微体系结构实现方式做过度的架构设计
    * 新的指令集，没有向后（backward）兼容的包袱
    * 说明书的页数少
* **模块化的指令集架构**
    * `RV32I`和`RV64I`是基础的`ISA`。可扩展增加其他特性的支持
    * 面向教育或科研，易于扩充或剪裁
    * 支持32位和64位地址空间
* **面向多核并行**
* **有效的指令编码方式**

**为什么学习微程序控制？**

1. 如何用一个结构简单的处理器实现复杂`ISA`
1. `CISC`机器怎么发展起来的
    * CISC指令集仍然广泛使用（`x86`、`IBM360`、`PowerPC`）
1. 帮助我们理解技术驱动从`CISC->RISC`

**微程序控制：**

* 每条`宏指令`是通过执行一段由若干条`微指令`构成的微程序来完成
* 微程序技术对计算机技术与产业发展起到了巨大的推动作用
* 可以采用简单的数据通路以及微程序控制器实现复杂的指令

**处理器设计可以分为`datapath`和`Control`设计两部分**

* `datapath`：存储数据、算术逻辑运算单元、内部处理器总线
* `control`：控制数据通路上的一系列操作

**60到70年代微程序盛行的原因**

1. `ROM`比`DRAM`要快的多
    * 微程序存放在`ROM`中实现扩展的复杂指令
1. 对于复杂的指令集，采用微程序设计技术使得`datapath`和`controller`更便宜、更简单
    * 新的指令（例如 floating point）可以在不修改数据通路情况下增加
    * 修改控制器的bug更容易
1. 不同型号的机器实现`ISA`的兼容性更简单、成本更低

**80年代初的微程序技术**

* 微程序技术的进展孕育了更复杂的微程序控制的机器
    * 复杂指令集导致`µcode`需要子程序和调用堆栈
    * 需要修复控制程序中的bug与`µROM`的只读属性冲突
* 随着超大规模集成电路技术的出现，有关`ROM`和`RAM`速度的假设变得无效
    * 逻辑部件、存储部件（`RAM`, `ROM`）均采用MOS晶体管实现
    * 半导体`RAM`与`ROM`的存取速度相同
* 随着编译器技术的进步，复杂指令变得不再那么重要
* 随着微结构技术的进步（pipeling, caches and buffers），使得多周期执行`reg-reg`指令失去了吸引力

## 2.4 相关课件

* [Chapter-2.1](/resources/System-Architecture/2-1.pdf)
* [Chapter-2.2](/resources/System-Architecture/2-2.pdf)
* [Chapter-2.3](/resources/System-Architecture/2-3.pdf)

# 3 基本流水线

## 3.1 基本流水线

**流水线的基本概念**

* 一个任务可以分解为`k`个子任务
    * `k`个子任务在`k`个不同阶段（使用不同的资源）运行
    * 每个子任务执行需要1个单位时间
    * 整个任务的执行时间为`k`倍单位时间
* 流水线执行模式是重叠执行模式
    * `k`个流水段并行执行`k`个不同任务
    * 每个单位时间进入/离开流水线一个任务
    * ![3-1](/images/计算机体系结构/3-1)

**流水线性能衡量：**

* 设{% raw %}$\tau_i = time\ delay\ in\ stage\ S_i${% endraw %}
* 时钟周期{% raw %}$\tau = max(\tau_i)${% endraw %}为最长的流水段延迟
* 时钟频率{% raw %}$f = \frac{1}{\tau} = \frac{1}{max(\tau_i)}${% endraw %}
* 流水线可以再`k + n -1`个时钟周期完成n个任务
    * 完成第一个任务需要`k`个时钟周期
    * 其他`n-1`个任务需要`n-1`个时钟周期
* `k`段流水线的理想加速比（相对于串行执行）
    * {% raw %}$S_k = \frac{Serial\ execution\ in\ cycles}{Pipelined\ execution\ in\ cycles}=\frac{nk}{k+n-1}${% endraw %}

**典型的RISC 5段指令流水线**

* 5个流水段，每段的延迟为1个cycle
* **`IF（Instruction Fetch）`：取指令阶段**
    * 选择地址：下一条指令地址、转移地址
* **`ID（Instruction Decode）`：指令译码**
    * 确定控制信号并从寄存器文件中读取寄存器值
* **`EX（Execute Address Calc）`：执行**
    * `Load/Store`：计算有效地址
    * `Branch`：计算转移地址并确定转移方向
* **`MEM（Memory Access）`：存储器访问（仅`Load`和`Store`）**
* **`WB（Write Back）`：结果写回**

**流水线的可视化表示：多条指令执行多个时钟周**

* 指令按程序序从上到下排列
* 图中展示了每一时钟周期资源的使用情况
* 不同指令相邻阶段之间没有干扰
* ![3-2](/images/计算机体系结构/3-2)

**流水线的技术要点：**

* **流水线的基本概念**
    * 多个任务重叠（并发/并行）执行，但使用不同的资源
    * 流水线技术提高整个系统的吞吐率，不能缩短单个任务的执行时间
    * 其潜在的加速比＝流水线的级数
* **流水线正常工作的基本条件**
    * 增加寄存器文件保存当前段传送到下一段的数据和控制信息
    * 需要更高的存储器带宽
* **流水线的相关`Hazards`问题**
    * 由于存在相关`Hazards`问题，会导致流水线停顿
    * `Hazards`问题：流水线的执行可能会导致对资源的访问冲突，或破坏对资源的访问顺序

**流水线的相关`Hazards`：**

* 结构相关：流水线中一条指令可能需要另一条指令使用的资源
* 数据和控制相关：一条指令可能依赖于先前的指令生成的内容
    * 数据相关：依赖先前指令产生的结果（数据）值
    * 控制相关：依赖关系是如何确定下一条指令地址（`branches`，`exceptions`）
* 处理相关的一般方法是插入`bubble`，导致`CPI>1`（单发射理想CPI）

**消减结构相关：**

* 当两条指令同时需要相同的硬件资源时，就会发生结构相关（冲突）
    * 方法1：通过将新指令延迟到前一条指令执行完（释放资源后）执行
    * 方法2：增加新的资源。例如，如果两条指令同时需要操作存储器，可以通过增加到两个存储器操作端口来避免结构冲突
* 经典的`RISC`5-段整型数流水线通过设计可以没有结构相关
    * 很多`RISC`实现在时存在结构相关。例如多周期操作的`multipliers`、`dividers`、`floating-point units`等，由于没有多个寄存器文件写端口导致结构冲突

**三种基本的数据相关：**

* **写后读相关：`RAW, Read After Write`**
* **读后写相关：`WAR, Write After Read`**
* **写后写相关：`WAW, Write After Write`**

**消减数据相关的三种策略：**

1. 联锁机制（`Interlock`）：在issue阶段保持当前相关指令，等待相关解除
1. 设置旁路定向路径（`Bypass or Forwarding`）：只要结果可用，通过旁路尽快传递数据
1. 投机（Speculate）：猜测一个值继续，如果猜测错了再更正。这种技术，仅在某些情况下可以使用
    * 分支预测
    * 堆栈指针更新
    * 存储器地址消除歧义

**延迟槽技术（`Branch Delay Slots`）**

* 对于分支跳转指令，在指令执行完毕之前，无法知道下一条指令的具体位置。而cpu又是流水线执行，因此需要插入一些空指令，这些空指令`NOP`所占据的时空就称谓延迟槽。更高级的做法是，将一些与分支跳转指令无关的指令，填充到这个延迟槽中，以提高指令执行效率
* 软件不得不填充延迟槽，即用`NOP`或者真实指令填充延迟槽

**`Post-1990 RISC ISAs`取消了延迟槽**

* 性能问题
    * 当延迟槽中填充了`NOP`指令后，增加了`I-Cache`的失效率
    * 即使延迟槽中只有一个`NOP`，`I-Cache`失效导致机器等待
* 使先进的微体系架构复杂化
* 分支预测技术的进步减少了采用延迟槽技术的动力

**解决控制相关的方法**

1. `Stall`直到分支方向确定
    * 可通过修改数据通路，减少`Stall`
1. 预测分支失败
    * 直接执行后继指令
    * 如果分支实际情况为分支成功，则撤销流水线中的指令对流水线状态的更新
    * 要保证：分支结果出来之前不会改变处理机的状态，以便一旦猜错时，处理机能够回退到原先的状态
1. 预测分支成功
    * 前提：先知道分支目标地址，后知道分支是否成功
1. 延迟转移技术

**为什么在经典的五段流水线中指令不能在每个周期都被分发`CPI>1`**

* 采用全定向路径可能代价太高而无法实现
    * 通常提供经常使用的定向路径
    * 一些不经常使用的定向路径可能会增加时钟周期的长度，从而抵消降低CPI的好处
* `Load`操作有两个时钟周期的延迟
    * Load指令后的指令不能马上使用`Load`的结果
    * `MIPS-I ISA`定义了延迟槽，软件可见的流水线冲突（由编译器调度无关的指令或插入`NOP`指令避免冲突），`MIPS-II`中取消了延迟槽语义（硬件上增加流水线`interlocks`机制）
* `Jumps/Conditional branches`可能会导致流水线断流（bubbles）
    * 如果没有延迟槽，则`Stall`后续的指令
* 带有软件可见的延迟槽有可能需要执行大量的由编译器插入的`NOP`指令`NOP`指令降低了`CPI`，增加了程序中执行的指令条数

**流水线的性能分析：**

* 衡量指标
    1. 吞吐率：假设`k`段，完成`n`个任务，单位时间所实际完成的任务数
    1. 加速比：`k`段流水线的速度与等功能的非流水线的速度之比
    1. 效率：流水线的设备利用率
* 影响流水线性能的因素
    * 流水线中的瓶颈——最慢的那一段
    * 流水段所需时间不均衡将降低加速比
    * 流水线存在装入时间和排空时间，使得加速比降低

**对`MIPS`的扩充：**

* `Integer`部件处理：`Loads`、`Store`、`Integer ALU`操作和`Branch`
* `FP/Integer`乘法部件：处理浮点数和整数乘法
* `FP`加法器：处理`FP`加，减和类型转换
* `FP/Integer`除法部件：处理浮点数和整数除法
* 这些功能部件未流水化

## 3.2 基本流水线的扩展

### 3.2.1 异常处理

**陷阱和中断：**

* 异常（Exception）:由程序执行过程中引起的异常「内部事件」
* 陷阱（Trap）:因异常情况而被迫将控制权移交给监控程序
* 中断（Interrupt）:响应（处理）程序之外的「外部事件」，导致控制权转移到监控程序
* 陷阱和中断通常由同样的流水线机制处理

**异步中断：**

* `I/O`设备通过发出中断请求信号来请求处理
* 当处理器决定响应该中断时
    * 停止当前指令`li`的执行，执行完当前指令前面的指令（执行完`li-1`） (精确中断）
    * 将`li`指令的`PC`值保存到专门寄存器`EPC`中
    * 关中断并将控制转移到以监控模式运行的指定的中断处理程序

**Interrupt Handler：**

* 允许嵌套中断时，在开中断之前需要保存`EPC`
    * 需要执行指令将`EPC`存入`GPRs`
    * 至少在保存EPC之前，需要一种方法来暂时屏蔽进一步的中断
* 需要读取记录中断原因的状态寄存器
* 使用专门的间接跳转指令`ERET` (`returnfrom-environment`) 返回
    * 开中断
    * 将处理器恢复到用户模式
    * 恢复硬件状态和控制状态

**Synchronous Trap：**

* 同步陷阱是由特定指令执行的异常引起的
* 通常，该指令无法完成，需要在处理异常之后重新启动
    * 需要撤消一个或多个部分执行的指令的效果
* 在系统调用（陷阱）的情况下，该特殊的跳转指令被认为已经完成
    * 一种特殊的跳转指令，涉及到切换到特权模式的操作

**Exception Handling：**

* 在流水线中将异常标志保留到提交阶段
* 在提交阶段并入异步中断请求 (抑制其他中断)
* 针对某一给定的指令，早期流水阶段中的异常抑制该指令的后续异常
* 如果提交时检测到异常：
    * 更新异常原因及`EPC`寄存器
    * 终止所有流水段
    * 将异常处理程序的地址送入`PC`寄存器，以跳转到处理程序中执行

**异常的推测：**

* **预测机制**
    * 异常总是比较少的，所以简单地预测为没有异常
* **检查预测机制**
    * 在指令执行的最后阶段进行异常检测
    * 采用专门的硬件用于检测各种类型的异常
* **恢复执行机制**
    * 仅在提交阶段改变机器状态，因此可以在发生异常后丢弃部分执行的指令
    * 刷新流水线后启动异常处理程序
* **定向路径机制允许后续的指令使用没有提交的指令结果**

### 3.2.2 多周期操作

**问题：**

* 浮点操作在1～2个`cycles`完成是不现实的，一般要花费较长时间
* 在MIPS中如何处理

**在1到2个`cycles`时间内完成的处理方法：**

* 采用较慢的时钟源，或
* 在`FP`部件中延迟其`EX`段

**现假设`FP`指令与整数指令采用相同的流水线，那么：****

* `EX`段需要循环多次来完成`FP`操作，循环次数取决于操作类型
* 有多个`FP`功能部件，如果发射出的指令导致结构或数据相关，需暂停

**`Latency`和`Repeat Interval`：**

* 延时`Latency`
    * 定义1：完成某一操作所需的`cycle`数
    * 定义2：使用当前指令所产生结果的指令与当前指令间的最小间隔周期数
* 循环间隔（Repeat/Initiation interval）
    * 发射相同类型的操作所需的间隔周期数
* 对于`EX`部件流水化的新的`MIPS`

| `Function Unit` | `Latency` | `Repeat Interval` |
|:--|:--|:--|
| Integer AU | 0 | 1 |
| Data Memory (Integer and FP loads(1 less for store latency)) | 1 | 1 |
| FP Add | 3 | 1 |
| FP multiply | 6 | 1 |
| FP Divide (also integer divide and FP sqrt) | 24 | 25 |

**将部分执行部件流水化后的`MIPS`流水线如下图**

![3-3](/images/计算机体系结构/3-3.png)

**新的相关和定向问题：**

* 结构冲突增多
    * 非流水的`Divide`部件，使得`EX`段增长24个`cycles`
* 在一个周期内可能有多个寄存器写操作
* 可能指令乱序完成（乱序到达`WB`段）有可能存在`WAW`
* 乱序完成导致异常处理复杂
* 由于指令的延迟加大导致`RAW`相关的`stall`数增多
* 需要付出更多的代价来增加定向路径

**解决方法：**

* 方法1
    * 在`ID`段跟踪写端口的使用情况，以便能暂停该指令的发射
    * 一旦发现冲突，暂停当前指令的发射
* 方法2
    * 在进入`MEM`或`WB`段时，暂停冲突的指令，让有较长延时的指令先做。这里假设较长延时的指令，可能会更容易引起其他`RAW`相关，从而导致更多的`stalls`

**精确异常与非精确异常：**

* **精确异常**
    * 如果流水线可以控制使得引起异常的指令前序指令都执行完，故障后的指令可以重新执行，则称该流水线支持精确异常
    * 按照指令的逻辑序处理异常
    * 理想情况，引起故障的指令没有改变机器的状态
    * 要正确的处理这类异常请求，必须保证故障指令不产生副作用
* **在有些机器上，浮点数异常**
    * 流水线段数多，在发现故障前，故障点后的指令就已经写了结果，在这种情况下，必须有办法处理
    * 很多高性能计算机，`Alpha 21164`、`MIPS R10000`等支持精确中断，但精确模式要慢10+倍，一般用在代码调试时，很多系统要求精确异常模式，如`IEEE FP`标准处理程序，虚拟存储器等
* **精确异常对整数流水线而言，不是太难实现**
    * 指令执行的中途改变机器的状态
    * 例如`IA-32`的自动增量寻址模式

**处理异常的4种可能的办法：**

* **方法1：忽略这种问题，当非精确处理**
    * 但现代计算机对`IEEE`浮点标准的异常处理，虚拟存储的异常处理要求必须是精确异常。
* **方法2：缓存操作结果，直到早期发射的指令执行完**
    * 当指令运行时间较长时，`Buffer`区较大
    * `future file`（Power PC620 MIPS R10000）
        * 缓存执行结果，按指令序确认
    * `history file`（CYBER 180/990）
        * 尽快确认
        * 缓存区存放原来的操作数，如果异常发生，回卷到合适的状态
* **方法3：以非精确方式处理，用软件来修正**
    * 为软件修正保存足够的状态
    * 让软件仿真尚未执行完的指令的执行
    * 例如
        * `Instruction 1 – A`执行时间较长，引起中断的指令
        * `Instruction 2, instruction 3, ….instruction n-1`未执行完的指令
        * `Instruction n`已执行完的指令
        * 由于第`n`条指令已执行完，希望中断返回后从第`n+1`条指令开始执行，如果我们保存所有的流水线的PC值，那么软件可以仿真`Instruction 1`到`Instruction n-1`的执行
* **方法4：暂停发射，直到确定先前的指令都可无异常的完成，再发射下面的指令**
    * 在EX段的前期确认（MIPS流水线在前三个周期中）
    * `MIPS R2K to R4K`以及`Pentium`使用这种方法

### 3.2.3 MIPS R4000

`MIPS R4000`是`64-bit`机器

* 主频`100MHz ~200MHz`
* 较深的流水线（级数较多）(有时也称为`superpipelining`)

**`MIPS R4000`的8级整数流水线：**

* `IF`：取指阶段前半部分，选择PC值，初始化指令`Cache`的访问
* `IS`：取指阶段后半部分，主要完成访问指令`Cache`的操作
* `RF`：指令译码，寄存器读取，相关检测及指令`Cache`命中检测
* `EX`：执行，包括计算有效地址，进行`ALU`操作，计算分支目标地址和检测分支条件
* `DF`：取数据，访问数据`Cache`的前半部分
* `DS`：访问数据`Cache`的后半部分
* `TC–tag`：检测，确定数据`Cache`是否命中
* `WB–Load`：操作和`R-R`操作的结果写回

## 3.3 小结

{% markmap %}

- 流水线
    - 标量流水线
        - 流水线提高的是指令带宽（吞吐率），而不是单条指令的执行速度
        - 相关限制了流水线性能的发挥
            - 结构相关：需要更多的硬件资源
            - 数据相关：需要定向，编译器调度
            - 控制相关：等待、分支预测、延迟槽
        - 编译器可降低数据相关和控制相关的开销
            - Load 延迟槽
            - Branch 延迟槽
            - 指令流静态调度
        - 浮点运算使得流水线控制更加复杂
            - 循环间隔（Repeat/Initiation interval）
            - 延时（Latency）
        - 增加流水线级数在提高性能的同时，会增加相关产生的可能性
        - 异常处理 引起控制流的变化，会冲刷流水线
    - 流水线性能分析
        - 吞吐率
        - 加速比
        - 效率
    - 异常处理
        - 广义的异常：异常和中断
            - 异常：程序运行过程中产生的内部事件，称为异常事件，因异常事件被迫将控制权转移到监控程序，称为陷阱（Trap）
            - 中断：响应（处理）程序之外的外部事件，导致控制权转移到监控程序
        - 同步异常 vs. 异步异常
            - 同步：可以精确定位产生异常的指令地址
            - 异步：没法精确定位产生异常的指令地址
        - 精确异常 vs. 非精确异常
            - 精确：响应异常后，可精确返回引起异常的指令位置
            - 非精确：响应异常后，无法精确返回引起异常的指令位置
        - 异常处理
            - 异常处理的时机：指令commit阶段 即最后完成阶段
            - 优先级：外部事件引起的异常，内部事件引起的异常（同一条指令按时间顺序）
            - 过程：保存现场、处理、恢复现场

{% endmarkmap %}

## 3.4 相关课件

* [Chapter-3.1](/resources/System-Architecture/3-1.pdf)
* [Chapter-3.2](/resources/System-Architecture/3-2.pdf)

# 4 存储层次结构设计

**存储层次结构：**

* **存储系统设计是计算机体系结构设计的关键问题之一**
    * 容量、价格、速度的权衡
* **用户对存储器的容量、价格和速度的要求是相互矛盾的**
    * 速度越快，每位价格就高
    * 容量越大，每位价格就低
    * 容量越大，速度就越慢
    * 目前主存一般由`DRAM`构成
* `Microprocessor`与`Memory`之间的性能差异越来越大
    * `CPU`性能提高大约`60%/year`
    * `DRAM`性能提高大约`9％/year`

**存储系统的设计目标：**

* **目标：针对典型应用平均访存时间最短**
* **途径：通过优化存储系统的组织**

**多级分层结构：`cpu -> M1 -> M2 -> ... -> Mn`**

* `M1`速度最快，容量最小，每位价格最高
* `Mn`速度最慢，容量最大，每位价格最低
* **存储系统接近`M1`的速度，容量和价格接近`Mn`**
* 并行

|  | `CPU` | `L1 Cache` | `L2 Cache` | `L3 Cache` | `Memory` | `I/O Device` |
|:--|:--|:--|:--|:--|:--|:--|
| `speed` | 300-500ps | 1-2ns | 3-10ns | 10-20ns | 50-100ns | 5-10ms |
| `capacity` | 500-1000B | 64KB | 256KB | 2-4MB | > 1GB | > 100GB | 

**存储层次工作原理：Locality**

* **应用程序局部性原理：给用户**
    * 一个采用低成本技术达到的存储容量（容量大，价格低）
    * 一个采用高速存储技术达到的访问速度（速度快）
* **Temporal Locality（时间局部性）**
    * 保持最近访问的数据项最接近微处理器
* **Spatial Locality（空间局部性）**
    * 以由地址连续的若干个字构成的块为单位，从低层复制到上一层

**存储层次结构涉及的基本概念**

* **Block**
    * 不同层次的Block大小可能不同
    * 命中和命中率
    * 失效和失效率
* **镜像和一致性问题**
    * 高层存储器是较低层存储器的一个镜像
    * 高层存储器内容的修改必须反映到低层存储器中
    * 数据一致性问题
* **寻址：不管如何组织，我们必须知道如何访问数据**
* **要求：不同层次上块大小可以不同**
    * 以块为单位进行数据交换
    * 不同级`Cache`块的大小可能不同
    * 页面（块）大小通常大于`Cache`块大小
    * 存在地址映射问题
    * 物理地址格式`Block Frame Address + Block Offset`

**存储层次的性能参数（假设采用二级存储：`M1`和`M2`，`M1`和`M2`的容量价格访问时间分别为`S1, C1, TA1`以及`S2, C2, TA2`）**

* **存储层次的平均每位价格`C`**
    * `C = (C1 * S1 + C2 * S2)/(S1 + S2)`
* **命中（`Hit`）：访问的块在存储系统的较高层次上**
    * 若一组程序对存储器的访问，其中`N1`次在`M1`中找到所需数据，`N2`次在`M2`中找到数据 则
    * `Hit Rate`（命中率）：存储器访问在较高层命中的比例`H = N1/(N1 + N2)`
    * `Hit Time`（命中时间）：访问较高层的时间，`TA1`
* **失效（`Miss`）：访问的块不在存储系统的较高层次上**
    * `Miss Rate（失效率）= 1 - (Hit Rate) = 1 - H = N2/(N1 + N2)`
    * 当在`M1`中没有命中时：一般必须从`M2`中将所访问的数据所在块搬到`M1`中，然后CPU才能在`M1`中访问
    * 设传送一个块的时间为`TB`，即不命中时的访问时间为：`TA2 + TB + TA1 = TA1 + TM`
        * `TM`通常称为失效开销
* **平均访存时间**
    * `TA = H * TA1 + (1 - H)(TA1 + TM) = TA1 + (1 - H)TM`：`平均访存时间 = 命中时间 + 失效率 * 失效开销`

**常见的存储层次的组织：**

* **`Registers<->Memory`：由编译器完成调度**
* **`Cache<->Memory`：由硬件完成调度**
* **`Memory<->Disk`：由硬件、操作系统、应用程序完成调度**

**在体系结构中，Cache无处不在**

* 寄存器：`Cache on variables`
* `1-2级Cache`：`Cache on memory`
* `Memory`：`Cache on hard disks`
    * `hard disk`可以视为主存的扩展（`VM`）

## 4.1 Cache的基本概念

**`Cache`**

* 小而快（`SRAM`）的存储技术
    * 存储正在访问的部分指令和数据
* 用于减少平均访存时间
    * 通过保持最近访问的数据在处理器附近来挖掘时间局部性
    * 通过以块为单位在不同层次移动数据来挖掘空间局部性
* 主要目标：
    * 提高访存速度
    * 降低存储系统成本

**`Cache`的四个问题**

1. 映像规则
1. 查找方法
1. 替换算法
1. 写策略

**映像规则：把一个块从主存调入`Cache`时，如何放置的问题**

* 全相联映像：即所调入的块可以放在`Cache`中的任何位置
* 直接相联映像：主存中每一块只能存放在`Cache`中的唯一位置
    * 一般，主存块地址`i`与`Cache`中块地址`j`的关系为：`j = i mod (M)`，其中`M`为`Cache`中的块数
* 组相联映像：主存中每一块可以被放置在`Cache`中唯一的一个组中的任意一个位置，组由若干块构成，若一组由`n`块构成，我们称`N`路组相联
    * 组间直接映像
    * 组内全映像
    * 如果`Cache`中有`G`组，则主存中第`i`块的组号`K = i mod (G)`

**不同相联度下的路数和组数，假设`Cache`的块数为`M`，每组由`N`个块构成，那么`Cache`的组数`G = M/N`**

* 相联度越高，`Cache`空间利用率就越高，块冲突概率就越小，失效率就越低
* `N`值越大，失效率就越低，但`Cache`的实现就越复杂，代价越大
* 现代大多数计算机都采用直接相联，两路或四路组相联

|  | 路数 | 组数 |
|:--|:--|:--|
| 全相联 | `M` | `1` |
| 直接相联 | `1` | `M` |
| 组相联 | `1 < N < M` |` 1 < G < M` |

**`Cache`查找方法**

* 在`Cache`中每一`block`都带有`tag`域（标记域），标记分为两类
    * Address Tags：标记所访问的单元在哪一块中，这样物理地址就分为三部分：`Address Tags ## Block index ## block Offset`
        * 全相联没有`Block Index`
        * `Address Tags`越短，查找所需代价就越小
    * `Status Tags`：标记该块的状态，如`Valid`、`Dirty`等
* 原则：所有可能的标记并行查找，`Cache`的速度至关重要，即并行查找
* 并行查找的方法
    * 用相联存储器实现，按内容检索
    * 用单体多字存储器和比较器实现
* 相联度`N`越大，实现查找的机制就越复杂，代价就越高
* 无论直接相联还是组相联，查找时，只需比较`tag`，`index`无需参加比较

**`Cache`替换算法**

* **主存中块数一般比`Cache`中的块多，可能出现该块所对应的一组或一个Cache块已全部被占用的情况，这时需强制腾出其中的某一块，以接纳新调入的块，替换哪一块，这是替换算法要解决的问题**
    * 直接映象，因为只有一块，别无选择
    * 组相联和全相联有多种选择
* **替换方法**
    * **随机法（Random)，随机选择一块替换**
        * 优点：简单，易于实现
        * 缺点：没有考虑`Cache`块的使用历史，反映程序的局部性较差，失效率较高
    * **`FIFO`－选择最早调入的块**
        * 优点：简单
        * 虽然利用了同一组中各块进入`Cache`的顺序，但还是反映程序局部性不够，因为最先进入的块，很可能是经常使用的块
    * **最近最少使用法（LRU, Least Recently Used）**
        * 优点：较好的利用了程序的局部性，失效率较低
        * 缺点：比较复杂，硬件实现较困难
* **实验结论**
    * 相联度高，失效率较低。
    * `Cache`容量较大，失效率较低。
    * `LRU`在`Cache`容量较小时，失效率较低
    * 随着`Cache`容量的加大，`Random`的失效率在降低

**`Cache写策略`**

* 程序对存储器读操作占`26％`， 写操作占`9％`
    * 写所占的存储器访问比例`9/(100+26+9)`大约为`7％`
    * 写所占访问数据`Cache`的比例：`9/(26+9)`大约为`25%`
* 大概率事件优先原则：优化`Cache`的读操作
* `Amdahl`定律：不可忽视写的速度
* 写策略就是要解决：何时更新主存问题
* **写命中（`Write Hit`）时的两种策略**
    * 写直达法（`Write Through`）：当写Cache命中时，`Cache`与主存同时发生写修改，因而较好的维护了与主存的内容一致性
        * 优点：易于实现，容易保持不同层次间的一致性
        * 缺点：速度较慢
    * 写回法（`Write Back`）：只修改`Cache`的内容，而不立即写入主存。只有当此行被换出时才写回主存
        * 优点：速度快，减少访存次数
        * 缺点：一致性问题
* **写失效（`Write Miss`）时的两种策略**
    * 什么是写失效？当我们要更新主存时，发现主存中存储的数据与`Cache`中不一致（换言之，`Cache`中的数据已过时）
    * 按写分配法（`Write Allocate`）：写失效时，先把所写单元所在块调入`Cache`，然后再进行写入，也称写时取（`Fetch on Write`）方法
    * 不按写分配法（`No-write Allocate`）：写失效时，直接写入下一级存储器，而不将相应块调入`Cache`，也称绕写法（`Write Around`）
    * 原则上以上两种方法都可以应用于写直达法和写回法，一般情况下
        * `Write Back`用`Write Allocate`
        * `Write Through`用`No-write Allocate`

## 4.2 Cache的基本优化方法

**Cache性能分析指标：**

* `CPU time = (CPU execution clock cycles + Memory stall clock cycles) ✖️ clock cycle time`
* `Memory stall clock cycles =  (Reads ✖️ Read miss rate ✖️ Read miss penalty) + (Writes ✖️ Write miss rate ✖️ Write miss penalty)`
* `Memory stall clock cycles = Memory accesses ✖️ Miss rate ✖️ Miss penalty`

**改进Cache性能的基本途径：**

* 降低失效率
    * 增加Cache块的大小
    * 增大Cache容量
    * 提高相联度
* 减小失效开销
    * 多级Cache
    * 使读失效优先于写失效
* 缩短命中时间
    * 避免在索引缓存期间进行地址转换

### 4.2.1 降低失效率

**`Cache`失效的原因可以分为三类**

* 强制性失效（`Compulsory`）
    * 第一次访问某一块，只能从下一级`Load`，也称为冷启动或首次访问失效
* 容量失效（`Capaticy`）
    * 如果程序执行时，所需块由于容量不足，不能全部调入`Cache`，则当某些块被替换后，若又重新被访问，就会发生失效
    * 可能会发生抖动现象
* 冲突失效（`Conflict/Collision`）
    * 组相联和直接相联的副作用
    * 若太多的块映像到同一组（块）中，则会出现该组中某个块被别的块替换（即使别的组或块有空闲位置)，然后又被重新访问的情况，这就属于冲突失效

**一些统计规律：**

* 相联度越高，冲突失效就越小
* 强制性失效和容量失效不受相联度的影响
* 强制性失效不受Cache容量的影响
* 容量失效随着容量的增加而减少
* `2:1Cache`经验规则：即大小为`N`的直接映象`Cache`的失效率约等于大小为`N/2`的两路组相联的`Cache`失效率

**降低失效率的方法：**

* **增大Cache容量**
    * 对冲突和容量失效的减少有利
* **增大块**
    * 减缓强制性失效
    * 可能会增加冲突失效（因为在容量不变的情况下，块的数目减少了）
* **通过预取可帮助减少强制性失效**
    * 必须小心不要把你需要的东西换出去
    * 需要预测比较准确（对数据较困难，对指令相对容易）

**块大小、容量的权衡：**

* **从统计数据可得到的结论**
    * 对于给定Cache容量，块大小增加时，失效率开始是下降，但后来反而上升
    * `Cache`容量越大，使失效率达到最低的块大小就越大
* **分析**
    * 块大小增加，可使强制性失效减少（空间局部性原理）
    * 块大小增加，可使冲突失效增加（Cache中块数量减少）
    * 失效开销增大（上下层间移动，数据传输时间变大）
* 设计块大小的原则，不能仅看失效率

**提高相联度**

* 8路组相联在降低失效率方面的作用已经和全相联一样有效
* 提高相联度，会增加命中时间

**`Victim Cache`**

* **基本思想**
    * 通常`Cache`为直接映象时冲突失效率较大
    * `Victim Cache`采用全相联，因此失效率较低
    * `Victim Cache`存放由于（冲突）失效而被丢弃的那些块
    * 失效时，首先检查`Victim Cache`是否有该块，如果有就将该块与`Cache`中相应块互换
* `Jouppi (DEC SRC)`发现
    * 含1到5项的`Victim Cache`对减少失效很有效，尤其是对于那些小型的直接映象数据`Cache`
    * 测试结果，项为4的`Victim Cache`能使`4KB`直接映象数据
    * `Cache`冲突失效减少20%-90%

### 4.2.2 减小失效开销

**基本手段：**

* 多级`Cache`技术（`Multilevel Caches`）
* 让读优先于写（`Giving Priority to Read Misses over Writes`）

**多级`Cache`**

* 一级`Cache`保持较小容量
    * 降低命中时间
    * 降低每次访问的能耗
* 增加二级`Cache`
    * 减少与存储器的`gap`
    * 减少存储器总线的负载
* 多级`Cache`的优点
    * 减少失效开销
    * 缩短平均访存时间（`AMAT`）
* 较大容量的`L2 Cache`可以捕捉许多`L1 Cache`的失效
    * 降低全局失效率

**多级包容性（`multilevel inclusive`）**

* `L1 Cache`的块总是存在于`L2 Cache`中
    * 浪费了`L2 Cache`空间，`L2`还应当有存放其他块的空间
* 在`L1`中`miss`，但在`L2`中命中，则从`L2`拷贝相应的块到`L1`
* 在`L1`和`L2`中均`miss`, 则从更低级拷贝相应的块到`L1`和`L2`
* 对`L1`写操作导致将数据同时写到`L1`和`L2`
* `Write Through`策略用于`L1`到`L2`
* `Write Back`策略可用于`L2`到更低级存储器，以降低存储总线的数据传输压力
* `L2`的替换动作（或无效）对`L1`可见
    * 即`L2`的一块被替换出去，那么其在`L1`中对应的块也要被替换出去
* `L1`和`L2`的块大小可以相同也可以不同

**多级不包容（Multilevel Exclusive）**

* `L1 Cache`中的块不会在`L2 Cache`中，以避免浪费空间
* 在`L1`中`miss`，但在`L2`中命中，将导致`Cache`间块的互换
* 在`L1`和`L2`均`miss`，将仅仅从更低层拷贝相应的块到`L1`
* `L1`的被替换的块移至`L2`
    * `L2`存储`L1`抛弃的块，以防后续`L1`还需要使用
* `L1`到`L2`的写策略为`Write-Back`
* `L2`到更低级`Cache`的写策略为`Write-Back`
* `AMD Athlon`：`64KB L1`、`256KB L2`

**多级`Cache`的性能分析**

* 局部失效率：该级`Cache`的失效次数`/`到达该级`Cache`的访存次数
* 全局失效率：该级`Cache`的失效次数`/`CPU发出的访存总次数
    * 全局失效率是度量`L2 Cache`性能的更好方法

**两级`Cache`的一些研究结论**

* 在`L2`比`L1`大得多得情况下，两级`Cache`全局失效率和容量与第二级`Cache`相同的单级`Cache`的失效率接近
* 局部失效率不是衡量第二级`Cache`的好指标
    * 它是第一级`Cache`失效率的函数
    * 不能全面反映两级`Cache`体系的性能
* 第二级Cache设计需考虑的问题
    * 容量：一般很大，可能没有容量失效，只有强制性失效和冲突失效
        * 相联度对第二级Cache的作用
        * `Cache`可以较大，以减少失效次数
    * 多级包容性问题：第一级`Cache`中的数据是否总是同时存在于第二级`Cache`中
        * 如果`L1`和`L2`的块大小不同，增加了多级包容性实现的复杂性

**让读失效优先于写**

* 由于读操作为大概率事件，需要读失效优先，以提高性能
* `Write Through Cache` -> `Write Buffer`（写缓冲），特别对写直达法更有效
    * `Write Buffer`：CPU不必等待写操作完成，即将要写的数据和地址送到`Write Buffer`后，CPU继续作其他操作
    * 写缓冲导致对存储器访问的复杂化
    * 解决问题的方法
        * 推迟对读失效的处理，直到写缓冲器清空，导致新的问题——读失效开销增大。
        * 在读失效时，检查写缓冲的内容，如果没有冲突，而且存储器可访问，就可以继续处理读失效
    * 写回法时，也可以利用写缓冲器来提高性能
        * 把脏块放入缓冲区，然后读存储器，最后写存储器
* `Write Back Cache` -> `Victim Buffer`
    * 被替换的脏块放到了`Victim Buffer`
    * 在脏块被写回前，需要处理读失效
    * 问题：`Victim Buffer`可能含有该读失效要读取的块
        * Solution：查找`Victim Buffer`，如果命中直接将该块调入Cache

## 4.3 Cache的高级优化方法

### 4.3.1 缩短命中时间

1. 小而简单的第一级`Cache`
1. 路预测方法

### 4.3.2 增加Cache带宽

1. `Cache`访问流水化
    * 提高`Cache`的带宽，有利于采用高相联度的缓存
    * `L1 Cache`的访问由多个时钟周期构成
    * 缺点
        * 增加了分支预测错误造成的额外开销
        * 增加了`Load`指令与要使用其结果的指令间的latency
        * 增加了`I-Cache`和`D-Cache`的延时
1. 无阻塞`Cache`
1. 多体`Cache`

### 4.3.3 减小失效开销

1. 关键字优先和提前重启
1. 合并写

### 4.3.4 降低失效率

1. 编译优化

### 4.3.5 通过并行降低失效开销或失效率

1. 硬件预取
1. 编译器控制的预取

## 4.4 存储器技术与优化

**存储器**

* 存储器的访问源
    * 取指令、取操作数、写操作数和`I/O`
* 存储器性能指标
    * 容量、速度和每位价格
    * 访问时间（Access Time）
    * 存储周期（Cycle Time）
* 种类：`DRAM`和`SRAM`
    * `Memory`：`DRAM`
    * `Cache`：`SRAM`

**`DRAM`**

* `DRAM`是由单个信息位构成的阵列
    * 通过行选择线和列选择线访问
    * 所有DRAM都由这些阵列构成
    * 不同的结构根据性能的需求选择的阵列数可能不同
* 所有`DRAM`的访问至少三个阶段
    * `Precharge`
    * `row access`
    * `column acces`
* `DRAM`的性能
    * `Latency`
        * 地址信号有效到第一组数据信号有效所需要的时间
        * 处理器发出请求到所请求的第一组数据到达处理器输入引脚所需要的`cycle`数
    * `Bandwidth`
        * 第一组数据到达后，后续数据到达的速率

**提高主存性能的方法：增大存储器的宽度（并行访问存储器）**

* 最简单直接的方法
* 优点：简单、直接，可有效增加带宽
* 缺点
    * 增加了CPU与存储器之间的连接通路的宽度，实现代价提高
    * 主存容量扩充时，增量应该是存储器的宽度
    * 写操作问题（部分写操作）
* 冲突问题
    * 取指令冲突，遇到程序转移时，一个存储周期中读出的n条指令中，后面的指令将无用
    * 读操作数冲突。一次同时读出的几个操作数，不一定都有用
    * 写操作冲突。这种并行访问，必须凑齐n个字之后一起写入。如果只写一个字，必须先把属于同一个存储字的数据读到数据寄存器中，然后在地址码的控制下修改其中一个字，最后一起写
    * 读写冲突。当要读写的字在同一个存储字内时，无法并行操作
* 冲突的原因
    * 从存储器本身看，主要是地址寄存器和控制逻辑只有一套

**采用简单的多体交叉存储器**

* 一套地址寄存器和控制逻辑
* 存储器组织为多个体（Bank）
* 存储体的宽度，通常为一个字，不需要改变总线的宽度
* 目的：在总线宽度不变的情况下，完成多个字的并行读写
* 存储模块中所包含的体数，为避免访问冲突，基本原则为：
    * 体的数目`>=`访问体中一个字所需的时钟周期数
    * 例如：某一向量机的存储系统，CPU发出访存请求10个时钟周期后，CPU将从存储体0得到一个字，随后体0开始读该存储体的下一个字，而CPU依次从其余7个存储体中得到后继的7个字。在第18个周期，CPU 将需要存储体0提供下一个字，但该字要到第20个时钟周期才被读出，CPU只好等待
* 缺陷：不能对单个体单独访问，对解决冲突没有帮助，逻辑上是一种宽存储器，对各个存储体的访问被安排在不同的时间段

## 4.5 虚拟存储器-基本原理

**虚拟存储器**

* 允许应用程序的大小，超过主存容量。目的是提高存储系统的容量
* 帮助OS进行多进程管理
    * 每个进程可以有自己的地址空间
    * 提供多个进程空间的保护
    * 可以将多个逻辑块映射到共享的物理存储器上
    * 静态重定位和动态重定位
        * 应用程序运行在虚地址空间
        * 虚实地址转换对用户是透明的
* 虚拟存储管理的是主存－辅助存储器这个层面上
    * 失效：页失效或地址失效
    * 块：页或段

**`Cache`与`VM`的区别**

* 目的不同
    * `Cache`是为了提高访存速度
    * `VM`是为了提高存储容量
* 替换的控制者不同
    * `Cache`失效由硬件处理
    * `VM`的页失效通常由OS处理
        * 一般页失效开销很大，因此替换算法非常重要
* 地址空间
    * `VM`空间由CPU的地址尺寸确定
    * Cache的大小与CPU地址尺寸无关
* 下一级存储器
    * `Cache`下一级是主存
    * `VM`下一级是磁盘，大多数磁盘含有文件系统，文件系统寻址与主存不同，它通常在I/O空间中，`VM`的下一级通常称为`SWAP`空间

**`VM`的四个问题**

1. 映像规则
1. 查找方法
1. 替换算法
1. 写策略

**映像规则**

* 选择策略：低失效率（复杂映象算法） vs. 高失效率（简单映射方法）
* 由于失效开销很大，一般选择低失效率方法，即全相联映射

**查找方法－用附加数据结构**

* 固定页大小－用页表
    * `VPN->PPN`
    * `Tag`标识该页是否在主存
* 可变长段－段表
    * 段表中存放所有可能的段信息
    * 段号->段基址再加段内偏移量
    * 可能存在许多小尺寸段
* 页表
    * 页表中所含项数：一般为虚页的数量
    * 功能：`VPN－>PPN`，方便页重新分配，有一位标识该页是否在内存

**替换规则**

* `LRU`是最好的
* 但真正的`LRU`方法，硬件代价较大
* 用硬件简化，通过OS来完成
    * 为了帮助OS寻找`LRU`页，每个页面设置一个`use bit`
    * 当访问主存中一个页面时，其`use bit`置位
    * OS定期复位所有使用位，这样每次复位之前，使用位的值反映了从上次复位到现在的这段时间中，哪些页曾被访问过
    * 当有失效冲突时，由OS来决定哪些页将被换出去

**写策略**

* 总是用写回法（`Write Back`），因为访问硬盘速度很慢

**页面大小的选择**

* 页面选择较大的优点
    * 减少了页表的大小
    * 如果局部性较好，可以提高命中率
* 页面选择较大的缺点
    * 内存中的碎片较多，内存利用率低
    * 进程启动时间长
    * 失效开销加大

**`TLB`：**

* 页表一般很大，存放在主存中
    * 导致每次访存可能要两次访问主存，一次读取页表项，一次读写数据
    * 解决办法：采用`TLB`
* `TLB`
    * 存放近期经常使用的页表项，是整个页表的部分内容的副本
    * 基本信息：`VPN##PPN##Protection Field##use bit ## dirty bit`
    * OS修改页表项时，需要刷新`TLB`，或保证`TLB`中没有该页表项的副本
    * TLB必须在片内
        * 速度至关重要
        * `TLB`过小，意义不大
        * `TLB`过大，代价较高
        * 相联度较高（容量小）

## 4.6 小结

{% markmap %}

- Cache基本概念
    - 存储系统分层
        - 为什么要这样做？
        - 为什么可以这样做？
    - 存储系统的性能指标：速度、容量、价格
        - 平均访存时间 = 命中时间 + 失效率 ✖️ 失效开销
    - Cache Q4
        - 映射规则
        - 查找方法
        - 替换策略
        - 写策略
- 基本Cache优化方法
    - 降低失效率：引起失效的3C
        - 增大Cache块
        - 增大Cache容量
        - 提高相联度
    - 减小失效开销
        - 多级Cache
        - 读失效优先于写失效
    - 缩短命中时间
        - 避免在缓存期间进行地址转换
- 高级Cache优化方法
    -  缩短命中时间
        - 小而简单的一级Cache
        - 路预测方法
    - 增加Cache带宽
        - Cache访问流水化
        - 无阻塞Cache
        - 多体Cache
    - 减小失效开销
        - 关键字优先和提前重启
        - 合并写
    - 降低失效率
        - 编译优化
    - 通过并行降低失效开销或失效率
        - 硬件预取
        - 编译器控制的预取

{% endmarkmap %}

## 4.7 相关课件

* [Chapter-4.1](/resources/System-Architecture/4-1.pdf)
* [Chapter-4.2](/resources/System-Architecture/4-2.pdf)
* [Chapter-4.3](/resources/System-Architecture/4-3.pdf)
* [Chapter-4.4](/resources/System-Architecture/4-4.pdf)

# 5 指令级并行

## 5.1 指令级并行的基本概念及静态指令流调度

**系统结构的`Flynn`分类：**

* **`SISD`**：单处理器模式
* **`SIMD`**：相同的指令作用在不同的数据
* **`MISD`**：无商业实现
* **`MIMD`**：通用性最强的一种结构，可用来挖掘线程级并行、数据级并行。组织方式可以是松耦合方式也可以是紧耦合方式

**并行的层级：**

* **请求级并行**
    * 多个任务可被分配到多个计算机上并行执行
* **进程级并行**
    * 进程可被调度到不同的处理器上并行执行
* **线程级并行**
    * 任务被组织成多个线程，多个线程共享一个进程的地址空间
    * 每个线程有自己独立的程序计数器和寄存器文件
* **数据级并行**
    * 单线程（逻辑上）中并行处理多个数据（`SIMD/Vectorexecution`）
    * 一个程序计数器，多个执行部件
* **指令级并行（`ILP`）**
    * 针对单一指令流，多个执行部件并行执行不同的指令

**指令级并行的基本概念及挑战：**

* `ILP`：无关的指令重叠（并行）执行
* 流水线的平均`CPI`
    * {% raw %}$\begin{split}Pipeline\ CPI\ =&\ Ideal\ Pipeline\ CPI\\&\ Struct\ Stalls\\&\ RAW\ Stalls\ +\ WAR\ Stalls\ +\ WAW\ Stalls\\&\ Control\ Stalls\\&\ Memory\ Stalls\end{split}${% endraw %}
* 本章研究：减少停顿（`stalls`）数的方法和技术
* 基本途径
    * 软件方法：
        * `gcc`：17%控制类指令，`5 instructions + 1 branch`
        * 在基本块上，得到更多的并行性
        * 挖掘循环级并行
    * 硬件方法
        * 动态调度方法
        * 以`MIPS`的浮点数操作为例

**循环展开**

* 基本块的定义：
    * 直线型代码，无分支
    * 单入口
    * 程序由分支语句连接基本块构成
* 循环级并行（`for (i = 1; i <= 1000; i++) x(i) = x(i) + s;`）
    * 循环展开对循环间无关的程序是有效降低`stalls`的手段
    * 指令调度，必须保证程序运行的结果不变
    * 注意循环展开中的`Load`和`Store`，不同次循环的`Load`和`Store`是相互独立的。需要分析对存储器的引用，保证他们没有引用同一地址（检测存储器访问冲突）
    * 不同次的循环，使用不同的寄存器（寄存器重命名）
    * 删除不必要的测试和分支后，需调整循环步长等控制循环的代码

**从编译器角度看代码移动**

* 编译器分析程序的相关性依赖于给定的流水线
* 编译器通过指令调度来消除相关
* 数据相关
    * 对于指令`i`和`j`，如果指令`j`使用指令`i`产生的结果，或指令`j`与指令`k`相关，并且指令`k`与指令`i`有数据相关
    * 如果相关，不能乱序执行
    * 对于寄存器比较容易确定（`fixed names`）
    * 但对`memory`的引用，比较难确定
* 另一种相关称为名相关（`name dependence`）：两条指令使用同名参数（`register or memory location`）但不交换数据
    * 反相关（`anti-dependence`）
        * 指令`j`所写的寄存器或存储单元，与指令`i`所读的寄存器或存储单元相同，注指令`i`先执行
    * 输出相关（`output dependence`）：（`WAW if a hazard for HW`）
        * 指令`i`和指令`j`对同一寄存器或存储单元进行写操作，必须保证两条指令的写顺序
    * 访问存储单元时，很难判断名相关
* 最后一种相关称为控制相关（`control dependence`）
    * 例如`if p1 {S1;};`：`S1`依赖于`P1`的测试结果
    * 处理控制相关的原则
        * 受分支指令控制的指令，不能移到控制指令之前，以免该指令的执行不在分支指令的控制范围
        * 不受分支指令控制的指令，不能移到控制指令之后，以免该指令的执行受分支指令的控制
    * 减少控制相关可以提高指令的并行性

## 5.2 硬件方法挖掘指令级并行

## 5.3 分支预测方法

## 5.4 基于硬件的推测执行

## 5.5 存储器访问冲突消解及多发射技术

## 5.6 多线程技术

## 5.7 相关课件

* [Chapter-5.1](/resources/System-Architecture/5-1.pdf)
* [Chapter-5.2](/resources/System-Architecture/5-2.pdf)
* [Chapter-5.3](/resources/System-Architecture/5-3.pdf)
* [Chapter-5.4](/resources/System-Architecture/5-4.pdf)
* [Chapter-5.5](/resources/System-Architecture/5-5.pdf)
* [Chapter-5.6](/resources/System-Architecture/5-6.pdf)
* [Chapter-5.7](/resources/System-Architecture/5-7.pdf)

# 6 数据级并行

## 6.1 相关课件

* [Chapter-6.1](/resources/System-Architecture/6-1.pdf)
* [Chapter-6.2](/resources/System-Architecture/6-2.pdf)
* [Chapter-6.3](/resources/System-Architecture/6-3.pdf)
* [Chapter-6.4](/resources/System-Architecture/6-4.pdf)

# 7 多处理器及线程级并行

## 7.1 相关课件

* [Chapter-7.1](/resources/System-Architecture/7-1.pdf)
* [Chapter-7.2](/resources/System-Architecture/7-2.pdf)
* [Chapter-7.3](/resources/System-Architecture/7-3.pdf)

# 8 缩写表

| 缩写 | 全称 |
|:--|:--|
| `ISA` | Instruction-Set Architecture |
| `VLIW` | Very Long Instruction Word |
| `EPIC` | Explicitly Parallel Instruction Computing |
| `CISC` | Complex Instruction Set Computer |
| `RISC` | Reduced Instruction Set Computer |
| `CPI` | Cycles per Instruction |
| `IPC` | Instruction per Cycle |
| `MIPS` | Millions of Instructions Per Second |
| `ABI` | Application Binary Interface |
| `ALU` | Arithmetic Logic Unit |
| `HL`/`ML` | High Level/Machine Level |
| `ROM` | Read-only Memory |
| `PROM` | Programmable Read-only Memory |
| `EPROM` | Erasable Programmable Read-only Memory |
| `EEPROM` | Electrically Erasable Programmable Read-only Memory |
| `FLASH` | FLASH EEPROM |
| `IF` | Instruction Fetch |
| `ID` | Instruction Decode |
| `EX` | Execute Address Calc |
| `MEM` | Memory Access |
| `WB` | Write Back |
| `RAW` | Read After Write |
| `WAR` | Write After Read |
| `WAW` | Write After Write |
| `PF` | Float Point |
| `DRAM` | Dynamic Random Access Memory |
| `SRAM` | Static Random Access Memory |    
| `DDR` | Double Data Rate |
| `VM` | Virtual Memory |
| `TLB` | Translation Look-aside Buffer |
| `SISD` | Single Instruction stream, Single Data stream |
| `SIMD` | Single Instruction stream, Multiple Data streams |
| `MISD` | Multiple Instruction streams, Single Data stream |
| `MIMD` | Multiple Instruction streams, Multiple Data streams |
| `ILP` | Instruction-Level Parallelism |

# 9 参考

* [计算机体系结构(Spring 2021)](http://staff.ustc.edu.cn/~xhzhou/CA-Spring2021/CA.html)
* 《Computer Architecture: A Quantitative Approach》