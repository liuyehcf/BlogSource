---
title: CMU-15-721
date: 2022-03-02 09:04:53
mathjax: true
tags: 
- 摘录
categories: 
- Database
---

**阅读更多**

<!--more-->

# 1 history

**`1960s - Integrated Data Store, IDS`**

* `Network data model`：见下图
* `Tuple-at-a-time`
* ![1-1](/images/CMU-15-721/1-1.png)

**`1960s - Information Management System, IMS`**

* `Hierarchical data model`：见下图
* `Programmer-defined physical storage format`
* `Tuple-at-a-time`
* ![1-2](/images/CMU-15-721/1-2.png)

**`1970s - Relational Model`**

* `Store database in simple data structures`
* `Access data through high-level language`
* `Physical storage left up to implementation`
* ![1-3](/images/CMU-15-721/1-3.png)
* 早期的实现包括
    * `System R`
    * `INGRES`
    * `Oracle`

**`1980s - Relational Model`**

* `Relation Model`在角逐中胜出，`SEQUEL`演变成为`SQL`
* `Oracle`在商业角逐中胜出
* `Stonebraker`创立了`Postgre`

**`1980s - Object-Oriented Databases`**

* 大多数这一阶段产生的`DBMS`在今天都不存在了，但是这些技术以另一种方式存在，比如`JSON/XML`等
* ![1-4](/images/CMU-15-721/1-4.png)
* ![1-5](/images/CMU-15-721/1-5.png)

**`1990s - Boring Days`**

* 这十年中，数据库系统没有重大进步
* 微软借鉴了`Sybase`，创立了`SQL Server`
* `Mysql`出现，作为`mSQL`的一种替代方案
* `Postgres`支持`SQL`
* `SQLite`在2000年早期出现

**`2000s - Internet Boom`**

* 网络大发展，分布式兴起
* 原有的数据库都是重量级且及其昂贵的，在分布式的场景中不再有优势
* 各大公司都独立开发中间件，用以支持`DBMS`的水平伸缩

**`2000s - Data Warehouses`**

* `OLAP`兴起
* `Relational / SQL`
* 分布式、`Shared-Noting`架构
* 列存大放异彩

**`2000s - NoSQL Systems`**

* 专注于高可用和高可扩展
* `Non-relational data model`，例如键值对
* 无`ACID`事务
* `API`取代了`SQL`

**`2010s - NewSQL`**

* 在支持`ACID`事务的同时，提供与`NoSQL`相当的性能
* `Relational / SQL`
* 分布式

**`2010s - Hybrid Systems`**

* `Hybrid Transactional-Analytical Processing, HTAP`
* 同时提供`OLTP`和`OLAP`的功能和性能
* 分布式、`Shared-Noting`架构
* `Relational / SQL`

**`2010s - Cloud Systems`**

* `DBaaS, Database-as-a-service`

**`2010s - Shared-Disk Engines`**

* 存储计算分离
* 通常用于数据湖（`Data Lake`）

**`2010s - Graph Systems`**

* 提供了针对图形的API
* 研究表明，尚不清楚使用以图形为中心的执行引擎和存储管理器是否有任何好处

**`2010s - Timeseries Systems`**

* 时序数据库，主要存储时序相关的数据

**`Andy's Thoughts`**

* 随着专用系统扩展其领域范围，`DBMS`类别的分界线将随着时间的推移而继续模糊
* 我相信关系模型和声明式查询语言促进了更好的数据工程

# 2 inmemory

## 2.1 Disk-Oriented DBMSs

**`Buffer Pool`**

**`Steal + No-Force`**

**示意图参考课件中的`7 ~ 13`页**

## 2.2 In-Memory DBMSs

**首批商用的`In-Memory DBMS`在`1990s`发布，包括：**

* `TimesTen`
* `DataBlitz`
* `Altibase`

**索引：**

* `1980s`提出了专门的主存索引，当时高速缓存和内存访问速度大致相当
* 但后来高速缓存的速度远远大于内存的访问速度时，内存优化索引的性能比`B+`树差，因为它们不支持缓存（为啥会不支持缓存）

**执行查询计划：**

* 由于数据都在内存中，顺序访问不再比随机访问快
* 传统的`tuple-at-a-time`的访问方式会因为函数调用的开销而变得很慢。这一情况在`OLAP`中更加突出

**`Logging & Recovery`**

* `In-Memory DBMS`也需要将`WAL`写入非易失性存储上，因为系统可能随时崩溃
* 由于不存在`Dirty Page`，因此无需追踪整个系统中的`LSN`

**性能瓶颈：对于`In-Memory DBMS`来说，`I/O`不再是性能瓶颈，同时其他开销也会被放大：**

* `Locking/Latching`
* `Cache-line misses`
* `Pointer chasing`
* `Predicate evaluations`
* `Data movement & copying`
* `Networking`

## 2.3 Concurrency Control Bottlenecks

对于`In-Memory DBMS`而言，事务获取锁的开销和访问数据的开销相当

* `DBMS`可以将`Lock Information`与数据存储在一起，提高`CPU Cache Locality`
* 需要用`CAS`替代`Mutex`

**`Concurrency Control Schemes`**

* `Two-Phase Locking, 2PL`
    * `DeadLock Detection`
    * `DeadLock Prevention`
    * **示意图参考课件中的`30 ~ 37`页**
* `Timestamp Ordering, T/O`
    * `Basic T/O`
    * `Optimistic Concurrency Control, OCC`
    * **示意图参考课件中的`40 ~ 63`页**

**仿真结果参考课件中的`71 ~ 75`页**

* `Schemes`
    * `DL_DETECT`：`2PL w/ DeadLock Detection`
    * `NO_WAIT`：`2PL w/ Non-waiting Prevention`
    * `WAIT_DIE``2PL w/ Wait-and-Die Prevention`
    * `TIMESTAMP`：`Basic T/O Algorithm`
    * `MVCC`：`Multi-Version T/O`
    * `OCC`：`Optimistic Concurrency Control`
* `Bottlenecks`
    * `Lock Thrashing`：`DL_DETECT`、`WAIT_DIE`
        * 按照`primary key`的顺序来获取锁，彻底消除死锁
    * `Timestamp Allocation`：`WAIT_DIE`、`All T/O Algorithm`
        * `Mutex`
        * `Atomic Addition`
        * `Batched Atomic Addition`
        * `Hardware Clock`
        * `Hardware Counter`
    * `Memory Allocations`：`OCC`、`MVCC`
        * 不要使用默认的`malloc`

# 3 mvcc1

`DBMS`对每个逻辑对象维护了多个物理版本

* 当事务写某个对象时，会创建该对象的一个新的物理版本
* 当事务读某个对象时，会读取事物开始时该对象的最新版本。用时间戳来判断可见性
* 写操作不阻塞读操作
* 读操作不阻塞写操作

**`Snapshot Isolation, SI`：**

* 若两个事务同时更新同一个对象，那么时间上较早写入的事务获胜
* 会产生`Write Skew Anomaly`，示意图参考课件中的`5 ~ 9`页

![3-1](/images/CMU-15-721/3-1.png)

**`MVCC`主要设计点：**

* `Concurrency Control Protocol`
    * ![3-2](/images/CMU-15-721/3-2.png)
    * `Timestamp Ordering`
        * `read-ts`：用于记录最近一次读取的时间
        * 若`Latch`未被其他事务持有，且`Tid`介于`begin-ts`和`end-ts`之间，那么该记录对事务`T`可见
        * 若`Latch`未被其他事务持有，且`Tid > read-ts`，那么事务`T`可以创建当前记录的一个新版本
    * `Optimistic Concurrency Control`
    * `Two-Phase Locking`
        * 使用`read-cnt`作为`Shared Lock`；使用`txn-id`以及`read-cnt`作为`Exclusive Lock`
        * 若`txn-id = 0`，那么递增`read-cnt`字段来表示获取`Shared Lock`
        * 若`txn-id = 0 && read-cnt == 0`，那么将`txn-id`设置成当前事务的`Tid`，且递增`read-cnt`字段来表示获取`Exclusive Lock`
    * **示意图参考课件中的`15 ~ 40`页**
* `Version Storage`
    * `Append-Only Storage`
        * 新版本会追加到`table`所在的同一个存储空间
        * `Version Chain Ordering`
            * `Oldest-to-Newest(O2N)`
                * 新版本追加到链的尾部
                * 查找时，需要遍历整个链
            * `Newest-to-Oldest(N2O)`
                * 新版本插入到链的首部，有额外的更新指针的操作
                * 查找时，无需遍历整个链
    * `Time-Travel Storage`
        * 维护两个数据表，一个叫做`Main Table`，另一个叫做`Time-Travel Table`
        * 每次更新时，都会将当前记录移动到`Time-Travel Table`
        * 同一记录的所有版本以`Newest-to-Oldest`的方式关联起来
    * `Delta Storage`
        * 维护两个数据表，一个叫做`Main Table`，另一个叫做`Delta Storage Segment`
        * 每次更新时，将数值的变化表达式记录到`Delta Storage Segment`中
        * 可以通过重放`Delta Storage Segment`来重建老的版本
    * `Non-Inline Attributes`
        * 维护两个数据表，一个叫做`Main Table`，另一个叫做`Variable-Length Data`
        * 通过指针复用那些在多个版本间没有变化的属性
            * 需要额外维护计数器
            * 内存分配复杂
        * ![3-3](/images/CMU-15-721/3-3.png)
* `Garbage Collection`
    * `DBMS`需要持续移除那些可回收的版本
        * 对任何事务都不可见的版本
        * 终止的事务创建的版本
    * 主要设计要点包括
        * 如何查找过期版本
        * 如何判断版本是否可回收
        * 到哪查找过期版本
    * 实现方式
        * `Tuple-Level`
            * 直接检查每个元组
            * `Background Vacuuming`：周期性地扫描数据表，由额外的线程池完成
            * `Cooperative Cleaning`：在事务查找最新的可见版本时，进行清理。由事务线程完成，只能用于`O2N`
        * `Transaction-Level`
            * 事务记录了数据修改前的版本，因此可以通过事务查找这些过期版本
* `Index Management`
    * `Primary Key Indexes`：总是指向`Version Chain Header`
    * `Secondary Indexes`：更加复杂
        * `Logical Pointers`
            * 每个`Tuple`需要维护一个固定的标识符（不同版本中，该标识符保持一致）
            * 需要一个中间层，来做标识符到物理地址的转换（物理地址指向`Version Chain Header`）
            * 标识符可以是`Primary Key`或者`Tuple Id`
        * `Physical Pointers`
            * 维护一个指向`Version Chain Header`的指针

**`MVCC Indexes`**

* `MVCC DBMS`通常不在索引上直接存储版本信息
* 索引需要支持`Duplicate Key`，同一个`Key`可能指向不同的`Logical Tuple Snapshot`
* **示意图参考课件中的`87 ~ 93`页**

# 4 mvcc2

## 4.1 Microsoft Hekaton (SQL Server)

**`Hekaton MVCC`：**

* 记录的每个版本都维护了两个时间戳
    * `BEGIN-TS`：活跃事务的`BeginTS`，或者是已提交事务的`CommitTS`
    * `END-TS`：`Infinity`，或者是已提交事务的`CommitTS`
    * **示意图参考课件中的`6 ~ 24`页**
* 维护了一个全局的`Transaction state map`
    * `ACTIVE`：事务进行中
    * `VALIDATING`：事务触发了`Commit`，且`DBMS`正在校验合法性
    * `COMMITTED`：事务已经结束，但是尚未修改由该事务创建的所有版本的时间戳
    * `TERMINATED`：事务已经结束，且已经修改由该事务创建的所有版本的时间戳
* ![4-1](/images/CMU-15-721/4-1.png)
* 只使用`Lock-Free`的数据结构
    * 唯一的串行点是时间戳的分配

## 4.2 TUM HyPer

**`HyPer MVCC`：**

* `Delta Storage`以及`Column Storage`
    * 非索引字段可以原地更新
    * 插入、删除操作会更新索引
    * `N2O Version Chain`
    * `No Predicate Locks`、`No Scan Checks`
* 通过直接终止那些试图修改未提交记录的事务，来避免写冲突
* **示意图参考课件中的`33 ~ 37`页（完全没看懂）**

## 4.3 SAP HANA

**`SAP HANA MVCC`：**

* `Time-Travel Storage`（`N2O`）
* `Main Data Table`中存储的是最老的版本
* 每个`Tuple`维护一个标识位，用于表示`Version Space`中是否有新版本
* 维护一个`Hash Table`，用于映射`Record Identifier`和`Version Chain Header`
* ![4-2](/images/CMU-15-721/4-2.png)

## 4.4 CMU Cicada

**`CMU Cicada MVCC`：**

* `In-Memory DBMS`
* `Append-Only-Storage`（`N2O`）
* `Best-effort Inlining`
    * ![4-3](/images/CMU-15-721/4-3.png)

## 4.5 Summary

**`MVCC Limitations`：**

* `Computation & Storage Overhead`
    * 大多数`MVCC`方案都会使用间接的方式来搜索`Version Chain`，这会增加`CPU Cache Miss`
    * 需要频繁的垃圾回收，来减小版本搜索的开销
* `Shared Memory Writes`
    * 大多数`MVCC`方案将版本信息存储在全局的内存中，而没有考虑局部性（`CPU Cache Miss`）
* `Timestamp Allocation`
    * 所有线程访问同一个`Counter`

**`OCC LIMITATIONS`：**

* `Frequent Aborts`
    * 频繁地终止事务，尤其是高并发场景下
* `Extra Reads & Writes`
    * 事务需要将记录拷贝到私有的空间，来保证可重复度
    * 同时，提交时需要检查读是否满足一致性
* `Index Contention`

# 5 mvcc3

## 5.1 MVCC Deletes

当一个`Tuple`的所有版本都逻辑删除后，`DBMS`才会对其进行物理删除

**如何表示逻辑删除？有如下两种方式：**

1. `Deleted Flag`
    * 在最新的版本后面增加一个标志位，用于表示逻辑删除
1. `Tombstone Tuple`
    * 创建一个空的物理版本来表示逻辑删除
    * 用一个独立的`Pool`来存储这些`Tombstone Tuple`，每个`Tombstone Tuple`只需要`1-bit`的存储空间

## 5.2 Garbage Collection

**设计要点：**

* `Index Clean-up`
* `Version Tracking Level`
    * `Tuple-Level`
        * `Background Vacuuming`
        * `Cooperative Cleaning`
    * `Transaction-Level`
    * `Epochs`
* `Frequency`：`Trade-off`，过于频繁，浪费CPU资源，且降低事务的效率；过于不频繁，浪费存储空间，降低版本查找的效率
    * `Periodically`：定期触发，或者某些指标达到阈值后触发
    * `Continuously`：将清理过程作为事务处理的一部分
* `Granularity`
    * `Single Version`
        * 单独追踪每个版本的可见性，单独回收
        * 控制粒度更细，但是开销大
    * `Group Version`
        * 以分组的方式管理版本，且以分组为单位进行回收。每个分组包含多个版本
        * 开销较低，但是会延迟回收（分组中的所有版本都可以回收时，才能回收整个分组）
    * `Table`（P29，没懂）
* `Comparison Unit`
    * `Timestamp`
        * 用一个全局最小的时间戳来判断版本是否可以回收
        * 实现简单
    * `Interval`
        * 用区间来判断可见性
        * 实现复杂

## 5.3 Block Compaction

`DBMS`需要将那些未满的块合并成更少的块，以减少内存使用量

# 6 oltpindexes1

## 6.1 In-Memory T-Tree

`B+ Tree`是为了提高在速度较低的存储介质上的访问速度。而`T-Tree`是针对内存数据库的一种替代方案，它基于`AVL Tree`

**`T-Tree`的节点包含如下属性**

* `Data Pointers`：指向数据的指针
* `Parent Pointer`：指向父节点的指针
* `Left Child Pointer`：指向左孩子的指针
* `Right Child Pointer`：指向右孩子的指针
* `Max-K`：当前节点指向的数据中的最大值。若`Key > Max-K`，那么`Key`可能存在于右孩子中
* `Min-K`：当前节点指向的数据中的最小值。若`Key < Min-K`，那么`Key`可能存在于左孩子中

**优势：**

* 由于其不直接存储节点数据，因此占用内存更少

**劣势：**

* 难以平衡
* 难以实现并发安全 

**示意图参考课件中的`7 ~ 22`页**

## 6.2 Latch-Free Bw-Tree

[Microsoft-bw-tree](https://www.microsoft.com/en-us/research/publication/the-bw-tree-a-b-tree-for-new-hardware/)

A new form of B tree, Bw-tree achieves its very high performance via a latch-free approach that effectively exploits the processor caches of modern multi-core chips.

### 6.2.1 Delta Updates

**更新时，生成对应的`Delta`，`Delta`指向原链表头，然后通过`CAS`操作替换`Mapping Table`中的指针，使其指向自己。若失败，则终止或重试**

![6-1](/images/CMU-15-721/6-1.png)

**示意图参考课件中的`23 ~ 40`页**

### 6.2.2 Garbage Collection

我们需要知道何时可以安全地为`Latch-Free Index`中的已删除节点回收内存

* `Reference Counting`
    * 计数为`0`时，可以删除
    * 在多核CPU上，并发性能较差。因为递增递减计数器，会导致大量的缓存一致性流量
    * 我们其实并不关心计数器的大小是多少，而只是希望在计数值为`0`的时候可以进行回收（允许延迟，不必立即回收）
* `Epoch-based Reclamation`（没懂）
    * 维护一个全局的`Epoch Counter`，并对其进行周期性地更新
        * 跟踪在一个`Epoch`期间哪些线程进入索引以及它们何时离开
    * 标记删除节点时标记节点的当前`Epoch`
        * 一旦所有线程都离开该`Epoch`，就可以回收该节点
    * 操作用一个`Epoch`进行标记
        * 每个`Epoch`都会跟踪属于它的线程以及可以回收的对象
        * 线程在每个操作之前加入一个`Epoch`，并发布可以为当前`Epoch`回收的对象（不一定是它加入的那个）
    * **示意图参考课件中的`49 ~ 57`页**
* `Hazard Pointers`

### 6.2.3 Structure Modifications

**`Split Delta Record`：**

* 标记`Page`的某个`Key Range`现在位于另一个`Page`
* 使用`Logical Pointer`指向`New Page`

**`Separator Delta Record`：**

* 在修改`Page`的`Parent`中记录`New Page`的搜索范围

**示意图参考课件中的`59 ~ 70`页**

## 6.3 B+ Tree Optimistic Latching

**优化1：`Pre-Allocated Delta Records`**

* 在`Page`中预先分配空间，用于存放`Delta`

**优化2：`Mapping Table Expansion`**

* 最高效的内存数据结构就是数组。但是为每个索引都分配一个完整的数组会比较浪费
* 使用虚拟内存分配整个数组。仅在访问对应偏移量的时候，才分配对应的物理内存（如何实现？？？）

# 7 oltpindexes2

## 7.1 Latches

**`Latch`方案的目标：**

* 更小的内存占用
* 执行效率更高（无冲突）
* 当前线程等待时间过长时，取消调度线程

**`Latch`的实现方案：**

* `Test-and-Set Spinlock`
    * 高效（指令简单）
    * 扩展性差，`Cache`不友好，`OS`不优化（在最坏的情况下，可能浪费大量CPU资源）
    * `std::atomic<T>`
* `Blocking OS Mutex`
    * 使用简单
    * 扩展性差（每个`lock`/`unlock`大约花费25ns）
    * `std::mutex`
* `Adaptive Spinlock`
    * 在用户态自旋一段时间
    * 若在自旋期间无法获取锁，就会让出CPU，并记录到`Parking Lot`中
    * 线程在进入自旋期间，看下是否有其他线程位于`Parking Lot`中，若是，择直接将自己挂起，避免无效自旋
    * 苹果的`WTF::ParkingLot`
* `Queue-based Spinlock`
    * 比`Mutex`更高效，且具有更好的`Cache Locality`
    * `std::atomic<Latch*>`
* `Reader-Writer Locks`
    * 允许并发读
    * 需要分别管理`Read Queue`、`Write Queue`，以防止饿死
    * 可以基于`Spinlock`实现

## 7.2 B+ Tree

**`B+ Tree`是一种平衡树，其访问、插入、删除的复杂度都是`O(log n)`**

**在访问一颗`B+ Tree`的过程中，需要获取或者释放`Latch`**

* 当某个节点的孩子节点都被认为是安全时，可以释放该节点的`Latch`
    * 安全意味着，不会发生`Split`以及`Merge`操作
* `Search`：从根节点开始，向下重复执行如下过程
    * 获取孩子节点的`Read Latch`
    * 释放父节点的`Read Latch`
* `Insert/Delete`：从根节点开始，向下重复执行如下过程
    * 获取孩子节点的`Write Latch`
    * 若孩子是安全的，那么释放该孩子节点的所有祖先节点的`Write Latch`
* **示意图参考课件中的`35 ~ 49`页**

**对于`Insert/Delete`的访问流程，由于直接沿路径加了`Write Latch`，这样很容易导致整个流程串行化，一个优化方式是：**

* 假设目标的`Leaf Node`是安全的，先用`Read Latch`访问，如果在访问路径中发现任何不安全的节点，再退回到上面这个版本
* **示意图参考课件中的`51 ~ 54`页**

**`Versioned Latch`**

* 每个节点维护一个版本信息（`Counter`）
* 写操作获取`Latch`时，会递增该版本信息（释放不会递减）
* 读操作查看`Latch`是否可用，但是不获取它，只是记录当时的版本信息。在读操作找到目标叶子节点后，再检查版本信息是否发生过变化。若发生过变化，那么终止或者重试读操作
* * **示意图参考课件中的`56 ~ 69`页（没看懂）**

## 7.3 Trie Index

`Trie Index`又称为字典树或者前缀树

* 其形状只依赖于`Key Space`以及其长度
* 不需要平衡操作
* 所有操作的复杂度是`O(k)`，其中`k`是`Key`的长度
* `Key`是隐式存储的，从根到叶节点的整条路径，表示了某个`Key`
* **示意图参考课件中的`75 ~ 83`页**

**`Radix Tree`**

* 作为唯一孩子节点的每个节点都与其父节点合并
* 又称为`Patricia Tree`
* 会产生假阳性（`False Positive`），所以`DBMS`需要再次校验`Key`是否匹配

### 7.3.1 Judy Array

**`Judy Array`是`256-Way Radix Tree`的变体，是第一种已知的能够实现自适应节点表示的`Radix Tree`：**

* 支持下三种类型：
    1. `Judy1`：将`Integer Key`映射成单个`bit, true or false`
    1. `JudyL`：将`Integer Key`映射成`Integer Value`
    1. `JudySL`：将`Variable-Length Key`映射成`Integer Value`
* 节点的元数据被打包成一个`128-bit`的`Judy Pointers`，存储在父节点中
    * `Node Type`
        * `Linear Node`：稀疏
            * 分为左右两部分，左边存储排序后的`Key`，右边存储对应于`Key`的指向孩子的指针
            * ![7-1](/images/CMU-15-721/7-1.png)
        * `Bitmap Node`：常规（好像理解的不太对）
            * 包含一个长度为256的`Bitmap`，用于表示某个`Key`是否存在（`Key`大小为`1-byte`，范围是0-255，正好作为`Bitmap`数组的下标）
            * 每`8-bit`一组，总共分为32组，可以隐式存储32个`Key`
            * ![7-2](/images/CMU-15-721/7-2.png)
            * ![7-3](/images/CMU-15-721/7-3.png)
        * `Uncompressed Node`：密集
            * 类似于下面要介绍的`ART-Node256`
    * `Population Count`
    * `Child Key Prefix / Value`
    * `64-bit Child Pointer`

### 7.3.2 ART

**`Adapative Radix Tree, ART`**

* [ART-Paper](/resources/The-Adaptive-Radix-Tree-ARTful-Indexing-for-Main-Memory-Databases.pdf)
* 被应用于`TUM HyPer DBMS`
* `256-Way Radix Tree`，基于分布，支持不同的节点类型
* 每个节点的元数据存储在其`Header`中

**`ART vs. Judy`**

* `Judy`有3中不同的节点类型。`ART`有4种不同的的节点类型（基于孩子的数量）
* `Judy`是一个通用的关联数组。它拥有键和值。`ART`是表索引，不需要覆盖完整的键，其值是指向元组的指针

**`ART`的节点类型：**

* `Node4`
    * `Node4`包含两个最大长度为4的数组，一个数组用于存储`Key`（`1-byte`），另一个用于存储`Pointer`（`8-byte`）。`Key`和`Pointer`一一对应。总大小是`1byte * 4 + 8byte * 4 = 36 byte`
    * ![7-4](/images/CMU-15-721/7-4.png)
* `Node16`
    * `Node16`，其结构与`Node4`类似，包含两个最大长度为8的数组，一个数组用于存储`Key`（`1-byte`），另一个用于存储`Pointer`（`8-byte`）。`Key`和`Pointer`一一对应。总大小是`1byte * 16 + 8byte * 16 = 144 byte`
    * 搜索时，可以采用二分查找，或者直接利用`SIMD`指令
    * ![7-5](/images/CMU-15-721/7-5.png)
* `Node48`
    * `Node48`结构上和`Node4`、`Node16`有所不同，包含两个长度不同的数组，一个数组长度是256，每个元素`1-byte`，另一个数组长度48，每个元素`8-byte`，用于存储`Pointer`。总大小是`1byte * 256 + 8byte * 48 = 640 byte`
        * 该结构隐式存储了48个`Key`。由于`Key`的大小是`1-byte`，其数值刚好是`0-255`，正好作为第一个数组的下标，第一个数组中存储的值，同时作为第二个数组的下标（由于第二个数组的长度是48，因此`1-byte`完全可以表示）
    * ![7-6](/images/CMU-15-721/7-6.png)
* `Node256`
    * `Node256`只有一个长度为256的数组，用于存储`Pointer`（`8-byte`）。总大小是`8byte * 256 = 2048 byte`
        * 该结构同样隐式存储了256个`Key`，由于`Key`的大小是`1-byte`，其数值刚好是`0-255`，正好作为数组的下标
        * 正因为`Node48`的`Pointer`数组只有48个元素，无法用`Key Byte`直接索引，于是才引入了一个长度为`256`，大小为`1-byte`的数组，充当第一级索引
    * ![7-7](/images/CMU-15-721/7-7.png)

### 7.3.3 Masstree

`Masstree`的每个节点都是一颗`B+ Tree`

![7-8](/images/CMU-15-721/7-8.png)

# 8 storage

## 8.1 Type Representation

* `int/bigint/smallint/tinyint`：直接用`C++`基本类型表示
* `float/real/numeric`：IEEE-754 Standard
    * 可变精度，存在精度损失
    * 计算效率高
* `decimal`：Fixed-point Decimals
* `time/date/timestamp`：`32/64-bit int`
* `varchar/varbinary/text/blob`
    * 指针
    * 包含当前长度和下一个位置的指针的`Header`

## 8.2 Data Layout / Alignment

以字对齐（`Word-Aligned`）的方式存储，能够显著提高吞吐率

* `No Alignment`
    * ![8-1](/images/CMU-15-721/8-1.png)
* `Alignment With Padding`
    * ![8-2](/images/CMU-15-721/8-2.png)
* `Alignment With Padding + Sorting`
    * ![8-3](/images/CMU-15-721/8-3.png)

## 8.3 Storage Models

**`N-ary Storage Model, NSM`：**

* 连续存储单个`Tuple`的所有属性
* `OLTP`的理想存储模型，因为`OLTP`通常读写单个`Tuple`，且经常会有批量插入操作
* 使用`tuple-at-a-time`的迭代模型
* 优势：
    * 插入、删除、更新操作快
    * 对于需要获取`Tuple`所有属性的查询更友好
    * 可以使用面向索引的存储
* 劣势：
    * 对于扫描全表的操作不友好
    * 对于需要获取`Tuple`部分属性的查询不友好

**`Decomposition Storage Model, DSM`：**

* 单独存储`Tuple`的每个属性
* `OLAP`的理想存储模型，因为`OLTP`通常会对某几个属性进行大范围或全表扫描
* 优势：
    * 无需读取不需要的属性
    * 更好的压缩性能
* 劣势：
    * 插入、删除、更新、点查较慢
* `Tuple Identification`
    * `Fixed-length Offsets`：`Tuple`中的每个属性的偏移量都是相同的
    * `Embedded Tuple Ids`：`Tuple`中的每个属性额外存储其`Tuple Id`
    * ![8-4](/images/CMU-15-721/8-4.png)
* `Data Organization`
    * `Insertion Order`
    * `Sorted Order`
    * `Partitioned`

**`Hybrid Storage Model`：**

* `Hot Data vs. Cold Data`
    * 数据插入后，有很大概率会被再次更新
    * 经过一段时间后，数据大概率只会被读取
* `Execution Engine`
    * `Separate Execution Engines`：针对`NSM`以及`DSM`两种存储模型，使用两个独立的`Execution Engine`
        * 需要合并来自两个引擎的结果
        * 需要事务跨两个引擎，那需要使用`2PC`
        * 实现方式有2种
            * `Fractured Mirrors`：Oracle, IBM
                * ![8-5](/images/CMU-15-721/8-5.png)
            * `Delta Store`：SAP HANA
                * ![8-6](/images/CMU-15-721/8-6.png)
    * `Single, Flexible Architecture`：使用一个能够兼容处理`NSM`以及`DSM`两种存储模型的`Execution Engine`
        * 不需要存储数据库的两个副本
        * 不需要同步`Database Segments`
        * 实现方式
            * `Peloton Ataptive Storage`
                * ![8-7](/images/CMU-15-721/8-7.png)

## 8.4 System Catalogs

几乎所有的`DBMS`以存储普通数据的方式存储`Cagalogs`。但由于`Catalogs`的特殊性，需要有专门的引导代码。`DDL`同样需要保证`ACID`

**`Schema Change`：**

* `Add Columns`
    * `NSM`：将元组复制到新区域
    * `DSM`：只需创建新的列
* `Drop Columns`
    * `NSM`：
        1. 将元组复制到新区域
        1. 标记为删除，后面再清理
    * `DSM`：只需删除列
* `Change Columns`

**`Indexes`：**

* `Create Index`
    * 扫描全表，并填充索引
    * 记录在扫描期间，由其他事务引起的变更
    * 扫描结束后，锁表，将扫描期间记录的变更更新到索引上
* `Drop Index`
    * 逻辑删除索引
    * 仅当删除索引的事务提交时，它才会变得不可见。在此之前，所有活跃的事务仍然需要更新它

## 8.5 小结

**`Hybrid Storage Model`已被抛弃，原因如下：**

* 工程实现的难度太大
* `Delta Version Storage + Column Store`与之等价
* `Catalog`实现难度大

# 9 compression

# 10 recovery

# 11 networking

# 12 scheduling

# 13 execution

# 14 compilation

# 15 vectorization1

# 16 vectorization2

# 17 hashjoins

# 18 sortmergejoins

# 19 optimizer1

# 20 optimizer2

# 21 optimizer3

# 22 costmodels

# 23 largerthanmemory

# 24 udfs

# 25 hardware

# 26 课件

* [Index of /spring2020/slides](https://15721.courses.cs.cmu.edu/spring2020/slides/)
1. [01-history](/resources/CMU-15-721/01-history.pdf)
1. [02-inmemory](/resources/CMU-15-721/02-inmemory.pdf)
1. [03-mvcc1](/resources/CMU-15-721/03-mvcc1.pdf)
1. [04-mvcc2](/resources/CMU-15-721/04-mvcc2.pdf)
1. [05-mvcc3](/resources/CMU-15-721/05-mvcc3.pdf)
1. [06-oltpindexes1](/resources/CMU-15-721/06-oltpindexes1.pdf)
1. [07-oltpindexes2](/resources/CMU-15-721/07-oltpindexes2.pdf)
1. [08-storage](/resources/CMU-15-721/08-storage.pdf)
1. [09-compression](/resources/CMU-15-721/09-compression.pdf)
1. [10-recovery](/resources/CMU-15-721/10-recovery.pdf)
1. [11-networking](/resources/CMU-15-721/11-networking.pdf)
1. [12-scheduling](/resources/CMU-15-721/12-scheduling.pdf)
1. [13-execution](/resources/CMU-15-721/13-execution.pdf)
1. [14-compilation](/resources/CMU-15-721/14-compilation.pdf)
1. [15-vectorization1](/resources/CMU-15-721/15-vectorization1.pdf)
1. [16-vectorization2](/resources/CMU-15-721/16-vectorization2.pdf)
1. [17-hashjoins](/resources/CMU-15-721/17-hashjoins.pdf)
1. [18-sortmergejoins](/resources/CMU-15-721/18-sortmergejoins.pdf)
1. [19-optimizer1](/resources/CMU-15-721/19-optimizer1.pdf)
1. [20-optimizer2](/resources/CMU-15-721/20-optimizer2.pdf)
1. [21-optimizer3](/resources/CMU-15-721/21-optimizer3.pdf)
1. [22-costmodels](/resources/CMU-15-721/22-costmodels.pdf)
1. [23-largerthanmemory](/resources/CMU-15-721/23-largerthanmemory.pdf)
1. [24-udfs](/resources/CMU-15-721/24-udfs.pdf)
1. [25-hardware](/resources/CMU-15-721/25-hardware.pdf)

# 27 Summary

{% markmap %}

- Buffer Pool
    - Design Goals
        - Accuracy
        - Correctness
        - Efficiency
        - Overhead
    - Replacement Policy
        - Least-Recently Used
        - Clock
        - LRU-K
        - Localization
        - Priority Hints
    - Dirty Pages
        - Background Writing
- MVCC
    - Concurrency Control Protocol
        - Timestamp Ordering
        - Optimistic Concurrency Control
        - Two-Phase Locking
    - Version Storage
        - Append-Only Storage
        - Time-Travel Storage
        - Delta Storage
    - Garbage Collection
        - Tuple-Level
            - Background Vacuuming
            - Cooperative Cleaning
        - Transaction-Level
    - Index Management
        - Primary Key Index
        - Secondary Index
            - Logical Pointer
            - Physical Pointer
- Index
    - B+ Tree
    - Bw Tree
    - Skip List
    - ART
        - Node4
        - Node16
        - Node48
        - Node256
    - Masstree
- Storage
    - Type Representation
    - Data layout
    - Storage Model
        - NSM
        - DSM
        - Hybrid Storage Model
    - System Catalog
{% endmarkmap %}

# 28 Else

1. Apache Arrow format
1. Delta: always refers to what changed
1. RCU, Read-Copy-Update
1. Latch vs. Lock
    * 本质上都是锁，锁的对象不同。Lock锁的对象是事务；而`Latch`锁的对象是一些内存资源（数据结构）
